#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á Telegram –∏ Asana
"""
from typing import Dict, List, Any, Tuple
from sync.reporter import analyze_coverage
from pipeline.telegram.vectorization.embeddings import cosine_similarity_embedding


def find_matching_tasks(
    sync_instance,
    telegram_tasks: List[Dict[str, Any]],
    asana_tasks: List[Dict[str, Any]],
    similarity_threshold: float = 0.75,
    verbose: bool = True,
    use_embeddings: bool = True,
    use_gpt5_verification: bool = False,
    low_threshold: float = 0.65,
    use_two_stage_matching: bool = True
) -> Dict[str, List[Tuple[Dict, Dict, float]]]:
    """
    –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –∏ –∫–µ—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    0. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á Asana —á–µ—Ä–µ–∑ GPT-5 Batch API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    1. –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö Telegram –∑–∞–¥–∞—á –±–∞—Ç—á–∞–º–∏
    2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –¥–ª—è –∫–∞–∂–¥–æ–π Telegram –∑–∞–¥–∞—á–∏
    3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á Asana –ø–æ –æ–∫–Ω–∞–º
    4. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (—Å –∫–µ—à–µ–º, –∏—Å–ø–æ–ª—å–∑—É—è —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏)
    5. GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    
    Args:
        telegram_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Telegram
        asana_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Asana
        similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0-1.0)
        verbose: –í—ã–≤–æ–¥–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
        use_embeddings: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        use_gpt5_verification: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPT-5 –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        low_threshold: –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        use_two_stage_matching: –î–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    
    Returns:
        Dict —Å –∫–ª—é—á–∞–º–∏: 'matches', 'telegram_only', 'asana_only', 'coverage'
    """
    matches = []
    telegram_matched = set()
    asana_matched = set()
    
    if verbose:
        print(f"   üìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(telegram_tasks)} Telegram √ó {len(asana_tasks)} Asana")
        if sync_instance.use_time_windows:
            print(f"   ‚è∞ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
        if sync_instance.embedding_cache:
            cache_stats = sync_instance.embedding_cache.get_cache_stats()
            print(f"   üíæ –ö–µ—à —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {cache_stats['local_cache_size']} –∑–∞–ø–∏—Å–µ–π")
        if sync_instance.use_task_summarization and sync_instance.task_summarizer:
            print(f"   üìù –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ GPT-5 Batch API")
    
    # –®–∞–≥ 0: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á Asana —á–µ—Ä–µ–∑ Batch API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
    if sync_instance.use_task_summarization and sync_instance.task_summarizer:
        if verbose:
            print(f"\n   üìù –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {len(asana_tasks)} –∑–∞–¥–∞—á Asana —á–µ—Ä–µ–∑ Batch API...")
        
        try:
            summarized_tasks = sync_instance.task_summarizer.summarize_tasks_batch(
                asana_tasks,
                verbose=verbose
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
            sync_instance._summarized_tasks_cache.update(summarized_tasks)
            
            if verbose:
                print(f"   ‚úÖ –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(summarized_tasks)} –∑–∞–¥–∞—á")
        except Exception as e:
            if verbose:
                print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
                print(f"   üí° –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
    
    # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö Telegram –∑–∞–¥–∞—á –±–∞—Ç—á–∞–º–∏ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞—Ç—Ä–∞—Ç)
    telegram_embeddings_map = {}
    if use_embeddings:
        if verbose:
            print(f"\n   üî¢ –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(telegram_tasks)} Telegram –∑–∞–¥–∞—á (–±–∞—Ç—á–∞–º–∏)...")
        
        telegram_texts = []
        telegram_indices = []
        
        for idx, tg_task in enumerate(telegram_tasks):
            tg_title = tg_task.get('title', '')
            tg_desc = tg_task.get('description', '')
            tg_context = tg_task.get('context', '')
            # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é:
            # title + description + –ø–µ—Ä–≤—ã–µ 1500 —Å–∏–º–≤–æ–ª–æ–≤ context (–≤–∞–∂–Ω–µ–µ –Ω–∞—á–∞–ª–æ)
            # –≠—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ, —Ç–∞–∫ –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å—Ä–µ–¥–Ω—è—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            tg_context_compact = tg_context[:1500] if tg_context else ''
            tg_text = f"{tg_title} {tg_desc} {tg_context_compact}".strip()[:8000]
            telegram_texts.append(tg_text)
            telegram_indices.append(idx)
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏ (—Å –∫–µ—à–µ–º)
        if sync_instance.embedding_cache:
            telegram_embeddings = sync_instance.embedding_cache.get_embeddings_batch(
                telegram_texts,
                client=sync_instance.openai_client,
                batch_size=100
            )
        else:
            # Fallback: –ø–æ–ª—É—á–∞–µ–º –±–∞—Ç—á–∞–º–∏ –±–µ–∑ –∫–µ—à–∞
            telegram_embeddings = []
            batch_size = 100
            for i in range(0, len(telegram_texts), batch_size):
                batch_texts = telegram_texts[i:i+batch_size]
                try:
                    response = sync_instance.openai_client.embeddings.create(
                        model="text-embedding-3-small",
                        input=batch_texts
                    )
                    batch_embeddings = [item.embedding for item in response.data]
                    telegram_embeddings.extend(batch_embeddings)
                    if verbose and (i // batch_size + 1) % 10 == 0:
                        print(f"      üì¶ –ë–∞—Ç—á {i // batch_size + 1}/{(len(telegram_texts)-1)//batch_size + 1}...", end='\r', flush=True)
                except Exception as e:
                    if verbose:
                        print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ {i // batch_size + 1}: {e}")
                    # –î–æ–±–∞–≤–ª—è–µ–º None –¥–ª—è –æ—à–∏–±–æ–∫
                    telegram_embeddings.extend([None] * len(batch_texts))
        
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å -> —ç–º–±–µ–¥–¥–∏–Ω–≥
        for idx, embedding in zip(telegram_indices, telegram_embeddings):
            telegram_embeddings_map[idx] = embedding
        
        if verbose:
            successful = sum(1 for emb in telegram_embeddings if emb is not None)
            print(f"\n      ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {successful}/{len(telegram_tasks)}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É Telegram
    for tg_idx, tg_task in enumerate(telegram_tasks, 1):
        tg_title = tg_task.get('title', '')
        tg_desc = tg_task.get('description', '')
        tg_context = tg_task.get('context', '')
        # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é:
        # title + description + –ø–µ—Ä–≤—ã–µ 1500 —Å–∏–º–≤–æ–ª–æ–≤ context (–≤–∞–∂–Ω–µ–µ –Ω–∞—á–∞–ª–æ)
        # –≠—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ, —Ç–∞–∫ –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å—Ä–µ–¥–Ω—è—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        tg_context_compact = tg_context[:1500] if tg_context else ''
        tg_text = f"{tg_title} {tg_desc} {tg_context_compact}".strip()[:8000]
        
        if verbose:
            print(f"\n   [{tg_idx}/{len(telegram_tasks)}] üì± Telegram: {tg_title[:60]}...")
        
        # –®–∞–≥ 1: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–¥–∞—á–∏ Asana
        windowed_tasks = {}
        if sync_instance.use_time_windows and sync_instance.time_window_matcher:
            windowed_tasks = sync_instance.time_window_matcher.prioritize_tasks_by_windows(tg_task, asana_tasks)
            
            if verbose:
                primary_count = len(windowed_tasks.get('primary', []))
                extended_count = len(windowed_tasks.get('extended', []))
                distant_count = len(windowed_tasks.get('distant', []))
                print(f"      ‚è∞ –û–∫–Ω–∞: –æ—Å–Ω–æ–≤–Ω–æ–µ={primary_count}, —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ={extended_count}, –¥–∞–ª—å–Ω–µ–µ={distant_count}")
        else:
            # –ë–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
            windowed_tasks = {
                'primary': asana_tasks,
                'extended': [],
                'distant': []
            }
        
        # –®–∞–≥ 2: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–∞–∑–≤–∞–Ω–∏–π
        tg_title_normalized = sync_instance.normalize_text(tg_title)
        best_match = None
        best_score = 0.0
        best_asana_idx = -1
        exact_match_found = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–∞—á–∞–ª–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ–∫–Ω–µ
        for window_name in ['primary', 'extended', 'distant']:
            window_tasks = windowed_tasks.get(window_name, [])
            for idx, asana_task in enumerate(window_tasks):
                if asana_task.get('gid') in asana_matched:
                    continue
                
                asana_name = asana_task.get('name', '')
                asana_name_normalized = sync_instance.normalize_text(asana_name)
                
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if tg_title_normalized == asana_name_normalized:
                    best_match = asana_task
                    best_score = 1.0
                    best_asana_idx = asana_task.get('gid')
                    exact_match_found = True
                    if verbose:
                        print(f"      ‚úÖ –¢–û–ß–ù–û–ï –°–û–í–ü–ê–î–ï–ù–ò–ï –ù–ê–ó–í–ê–ù–ò–ô! Score: 1.00 ‚Üí {asana_name[:50]}")
                    break
                
                # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if tg_title_normalized in asana_name_normalized or asana_name_normalized in tg_title_normalized:
                    shorter = min(len(tg_title_normalized), len(asana_name_normalized))
                    longer = max(len(tg_title_normalized), len(asana_name_normalized))
                    if shorter > 0:
                        partial_score = shorter / longer
                        if partial_score > 0.7 and partial_score > best_score:
                            best_match = asana_task
                            best_score = partial_score
                            best_asana_idx = asana_task.get('gid')
                            exact_match_found = True
                            if verbose:
                                print(f"      ‚úÖ –ß–ê–°–¢–ò–ß–ù–û–ï –°–û–í–ü–ê–î–ï–ù–ò–ï –ù–ê–ó–í–ê–ù–ò–ô! Score: {partial_score:.2f} ‚Üí {asana_name[:50]}")
            
            if exact_match_found:
                break
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if exact_match_found and best_score >= similarity_threshold:
            matches.append((tg_task, best_match, best_score))
            telegram_matched.add(tg_idx - 1)
            asana_matched.add(best_asana_idx)
            if verbose:
                print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ! Score: {best_score:.2f}")
            continue
        
        # –®–∞–≥ 3: –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if use_embeddings:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ (–±–∞—Ç—á–∞–º–∏)
                tg_embedding = telegram_embeddings_map.get(tg_idx - 1)
                
                if not tg_embedding:
                    if verbose:
                        print(f"      ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                
                # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö –æ–∫–æ–Ω —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
                all_candidates = []
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–∫–Ω–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
                for window_name, window_tasks in [
                    ('primary', windowed_tasks.get('primary', [])),
                    ('extended', windowed_tasks.get('extended', [])),
                    ('distant', windowed_tasks.get('distant', []))
                ]:
                    if not window_tasks:
                        continue
                    
                    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∑–∞–¥–∞—á –≤ –æ–∫–Ω–µ (—Å –∫–µ—à–µ–º)
                    asana_texts = []
                    asana_indices = []
                    
                    for idx, asana_task in enumerate(window_tasks):
                        if asana_task.get('gid') in asana_matched:
                            continue
                        
                        context = sync_instance.extract_asana_task_context(asana_task)
                        # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é (–ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è)
                        asana_text = context.get('embedding_text', context['full_text'])[:8000]
                        asana_texts.append(asana_text)
                        asana_indices.append((idx, asana_task))
                    
                    if not asana_texts:
                        continue
                    
                    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏ (—Å –∫–µ—à–µ–º)
                    # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞—Ç—á–∏–Ω–≥ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç
                    if sync_instance.embedding_cache:
                        asana_embeddings = sync_instance.embedding_cache.get_embeddings_batch(
                            asana_texts,
                            client=sync_instance.openai_client,
                            batch_size=100  # OpenAI –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ 2048, –∏—Å–ø–æ–ª—å–∑—É–µ–º 100 –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                        )
                    else:
                        # Fallback: –±–∞—Ç—á–∏–Ω–≥ –±–µ–∑ –∫–µ—à–∞ (–≤–∞–∂–Ω–æ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç)
                        asana_embeddings = []
                        batch_size = 100
                        for i in range(0, len(asana_texts), batch_size):
                            batch_texts = asana_texts[i:i+batch_size]
                            try:
                                response = sync_instance.openai_client.embeddings.create(
                                    model="text-embedding-3-small",
                                    input=batch_texts
                                )
                                batch_embeddings = [item.embedding for item in response.data]
                                asana_embeddings.extend(batch_embeddings)
                            except Exception as e:
                                if verbose:
                                    print(f"         ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ Asana: {e}")
                                # –î–æ–±–∞–≤–ª—è–µ–º None –¥–ª—è –æ—à–∏–±–æ–∫
                                asana_embeddings.extend([None] * len(batch_texts))
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
                    for (idx, asana_task), embedding in zip(asana_indices, asana_embeddings):
                        if embedding is None:
                            continue
                        
                        similarity = cosine_similarity_embedding(tg_embedding, embedding)
                        
                        # –ü–æ—Ä–æ–≥–∏ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –æ–∫–Ω–∞
                        if window_name == 'primary':
                            min_score = low_threshold
                        elif window_name == 'extended':
                            min_score = low_threshold + 0.05  # –ß—É—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥
                        else:  # distant
                            min_score = similarity_threshold  # –¢–æ–ª—å–∫–æ –≤—ã—Å–æ–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                        
                        if similarity >= min_score:
                            all_candidates.append({
                                'task': asana_task,
                                'score': similarity,
                                'window': window_name,
                                'gid': asana_task.get('gid')
                            })
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ score
                all_candidates.sort(key=lambda x: x['score'], reverse=True)
                
                # –ë–µ—Ä–µ–º —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–º–∞–∫—Å–∏–º—É–º 5 –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ–∫–Ω–∞, 3 –∏–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ, 2 –∏–∑ –¥–∞–ª—å–Ω–µ–≥–æ)
                top_candidates = []
                primary_count = 0
                extended_count = 0
                distant_count = 0
                
                for candidate in all_candidates:
                    window = candidate['window']
                    if window == 'primary' and primary_count < 5:
                        top_candidates.append(candidate)
                        primary_count += 1
                    elif window == 'extended' and extended_count < 3:
                        top_candidates.append(candidate)
                        extended_count += 1
                    elif window == 'distant' and distant_count < 2:
                        top_candidates.append(candidate)
                        distant_count += 1
                
                if top_candidates:
                    best_candidate = top_candidates[0]
                    best_match = best_candidate['task']
                    best_score = best_candidate['score']
                    best_asana_idx = best_candidate['gid']
                    
                    if verbose:
                        print(f"      üî¢ –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {best_score:.3f} (–æ–∫–Ω–æ: {best_candidate['window']}) ‚Üí {best_match.get('name', '')[:50]}")
                    
                    # –î–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                    needs_gpt5_check = False
                    if use_two_stage_matching and low_threshold <= best_score < similarity_threshold:
                        needs_gpt5_check = True
                        if verbose:
                            print(f"         ‚ö†Ô∏è  –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (score {best_score:.3f} < –ø–æ—Ä–æ–≥–∞ {similarity_threshold}), —Ç—Ä–µ–±—É–µ—Ç—Å—è GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞")
                    
                    # GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞
                    # –î–ª—è GPT-5 –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç (full_text) –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    if needs_gpt5_check or (use_gpt5_verification and best_score >= similarity_threshold):
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ context –¥–ª—è GPT-5 (–ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ)
                        best_match_context = sync_instance.extract_asana_task_context(best_match)
                        asana_text_full = best_match_context['full_text']
                        
                        # –î–ª—è Telegram —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π context –ø—Ä–∏ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–µ
                        tg_text_full = f"{tg_title} {tg_desc} {tg_context}".strip()[:8000]
                        
                        try:
                            gpt5_score = sync_instance.calculate_similarity(tg_text_full, asana_text_full, verbose=verbose)
                            if verbose:
                                if needs_gpt5_check:
                                    print(f"         üîç GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {best_score:.3f} ‚Üí {gpt5_score:.2f}")
                                else:
                                    print(f"         üîç GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞: {best_score:.3f} ‚Üí {gpt5_score:.2f}")
                            
                            if gpt5_score >= similarity_threshold:
                                best_score = gpt5_score
                                if verbose and needs_gpt5_check:
                                    print(f"         ‚úÖ GPT-5 –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ!")
                            else:
                                if exact_match_found:
                                    if verbose:
                                        print(f"         ‚ö†Ô∏è  GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π")
                                else:
                                    if verbose and needs_gpt5_check:
                                        print(f"         ‚ùå GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ")
                                    best_match = None
                                    best_score = 0.0
                                    best_asana_idx = -1
                        except Exception as e:
                            if verbose:
                                print(f"         ‚ö†Ô∏è  –û—à–∏–±–∫–∞ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
                            if needs_gpt5_check:
                                best_match = None
                                best_score = 0.0
                                best_asana_idx = -1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
                if best_match and best_score >= similarity_threshold:
                    matches.append((tg_task, best_match, best_score))
                    telegram_matched.add(tg_idx - 1)
                    asana_matched.add(best_asana_idx)
                    if verbose:
                        print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ! Score: {best_score:.2f} ‚Üí {best_match.get('name', '')[:50]}")
                else:
                    if verbose:
                        print(f"      ‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ—Ä–æ–≥: {similarity_threshold})")
            
            except Exception as e:
                if verbose:
                    print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {e}")
                    import traceback
                    traceback.print_exc()
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –Ω–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if not best_match and verbose:
            print(f"      ‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Telegram
    telegram_only = [
        tg_task for idx, tg_task in enumerate(telegram_tasks)
        if idx not in telegram_matched
    ]
    
    # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Asana
    asana_only = [
        asana_task for asana_task in asana_tasks
        if asana_task.get('gid') not in asana_matched
    ]
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è
    coverage_analysis = analyze_coverage(matches, telegram_tasks, asana_tasks, sync_instance.context_extractor)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–µ—à –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º (–µ—Å–ª–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è)
    if sync_instance.embedding_cache:
        sync_instance.embedding_cache.flush_cache()
        if verbose:
            sync_instance.embedding_cache.print_cache_stats()
    
    return {
        'matches': matches,
        'telegram_only': telegram_only,
        'asana_only': asana_only,
        'coverage': coverage_analysis
    }

