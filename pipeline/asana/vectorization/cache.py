"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–µ—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à –∏ –∫–µ—à OpenAI
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–µ—à–∞ –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏
"""
import json
import hashlib
import time
import sys
from pathlib import Path
from typing import List, Optional, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
_script_dir = Path(__file__).resolve().parent
_project_root = _script_dir.parent.parent.parent.parent.parent  # cache -> vectorization -> asana -> pipeline -> ai-pmtool
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))

from shared.ai.gpt5_client import get_openai_client


class EmbeddingCache:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–µ—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    
    def __init__(
        self,
        cache_dir: Optional[Path] = None,
        use_local_cache: bool = True,
        use_openai_cache: bool = True
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–µ—à–∞
        
        Args:
            cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–µ—à–∞
            use_local_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à
            use_openai_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–µ—à OpenAI (–ø–∞—Ä–∞–º–µ—Ç—Ä cache_control)
        """
        self.use_local_cache = use_local_cache
        self.use_openai_cache = use_openai_cache
        self.cache_dir = cache_dir or Path(__file__).parent.parent.parent.parent / "cache" / "embeddings"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.local_cache_file = self.cache_dir / "embeddings_cache.json"
        self.local_cache = self._load_local_cache()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–µ—à–∞
        self.cache_stats = {
            'hits': 0,      # –ü–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫–µ—à
            'misses': 0,    # –ü—Ä–æ–º–∞—Ö–æ–≤ (–Ω—É–∂–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å —É API)
            'saves': 0      # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π –≤ –∫–µ—à
        }
        
        # –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π (—á—Ç–æ–±—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        self.cache_modified = False
        
        self.openai_client = None
    
    def _load_local_cache(self) -> Dict[str, Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à –∏–∑ —Ñ–∞–π–ª–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {hash: {embedding, model, text_preview, created_at, last_used_at}}
        """
        if not self.use_local_cache or not self.local_cache_file.exists():
            return {}
        
        try:
            with open(self.local_cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∫–µ—à–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
                if not cache_data:
                    return {}
                
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞
                first_value = next(iter(cache_data.values()))
                if isinstance(first_value, dict) and 'embedding' in first_value:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    if 'created_at' in first_value:
                        # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                        return cache_data
                    else:
                        # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
                        converted_cache = {}
                        current_time = time.time()
                        for key, value in cache_data.items():
                            if isinstance(value, dict) and 'embedding' in value:
                                converted_cache[key] = {
                                    **value,
                                    'created_at': current_time,
                                    'last_used_at': current_time
                                }
                        return converted_cache
                else:
                    # –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                    print(f"      ‚ö†Ô∏è  –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–µ—à–∞, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π")
                    return {}
        except Exception as e:
            print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–µ—à–∞: {e}")
            return {}
    
    def _save_local_cache(self, force: bool = False):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à –≤ —Ñ–∞–π–ª
        
        Args:
            force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        """
        if not self.use_local_cache:
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
        if not force and not self.cache_modified:
            return
        
        try:
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
            if self.local_cache_file.exists():
                backup_file = self.local_cache_file.with_suffix('.json.backup')
                try:
                    import shutil
                    shutil.copy2(self.local_cache_file, backup_file)
                except Exception:
                    pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
            
            with open(self.local_cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.local_cache, f, ensure_ascii=False, indent=2)
            
            self.cache_modified = False
        except Exception as e:
            print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫–µ—à–∞: {e}")
    
    def flush_cache(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–µ—à (–≤—ã–∑—ã–≤–∞—Ç—å –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º)"""
        self._save_local_cache(force=True)
    
    def _get_text_hash(self, text: str) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–µ—à–∞"""
        return hashlib.sha256(text.encode('utf-8')).hexdigest()
    
    def get_embedding(
        self,
        text: str,
        model: str = "text-embedding-3-small",
        client=None
    ) -> Optional[List[float]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–µ—à–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            client: OpenAI –∫–ª–∏–µ–Ω—Ç (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
            
        Returns:
            –≠–º–±–µ–¥–¥–∏–Ω–≥ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if not text or not text.strip():
            return None
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–µ—à–∞
        normalized_text = text.strip()[:8000]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ OpenAI
        text_hash = self._get_text_hash(normalized_text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à
        if self.use_local_cache and text_hash in self.local_cache:
            cached_data = self.local_cache[text_hash]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å —Å–æ–≤–ø–∞–¥–∞–µ—Ç
            if cached_data.get("model") == model:
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                cached_data["last_used_at"] = time.time()
                self.cache_stats['hits'] += 1
                return cached_data.get("embedding")
        
        # –ü—Ä–æ–º–∞—Ö –∫–µ—à–∞
        self.cache_stats['misses'] += 1
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –∫–µ—à–µ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É OpenAI
        if client is None:
            client = get_openai_client()
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à OpenAI –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            kwargs = {
                "model": model,
                "input": normalized_text
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º cache_control –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è OpenAI
            if self.use_openai_cache:
                # OpenAI cache control (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è API)
                # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–∑–æ–≤, –∫–µ—à OpenAI —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                pass
            
            response = client.embeddings.create(**kwargs)
            embedding = response.data[0].embedding
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à
            if self.use_local_cache:
                current_time = time.time()
                self.local_cache[text_hash] = {
                    "text": normalized_text[:100],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–≤—å—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    "model": model,
                    "embedding": embedding,
                    "created_at": current_time,
                    "last_used_at": current_time
                }
                self.cache_stats['saves'] += 1
                self.cache_modified = True
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ (–Ω–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞)
                if self.cache_stats['saves'] % 10 == 0:
                    self._save_local_cache()
            
            return embedding
        except Exception as e:
            print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None
    
    def get_embeddings_batch(
        self,
        texts: List[str],
        model: str = "text-embedding-3-small",
        batch_size: int = 100,
        client=None
    ) -> List[Optional[List[float]]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –±–∞—Ç—á–∞–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–µ—à–∞
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            client: OpenAI –∫–ª–∏–µ–Ω—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å None –¥–ª—è –æ—à–∏–±–æ–∫)
        """
        if client is None:
            client = get_openai_client()
        
        embeddings = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]
            batch_embeddings = []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –≤ –±–∞—Ç—á–µ
            texts_to_fetch = []
            indices_to_fetch = []
            
            for idx, text in enumerate(batch_texts):
                if not text or not text.strip():
                    batch_embeddings.append(None)
                    continue
                
                normalized_text = text.strip()[:8000]
                text_hash = self._get_text_hash(normalized_text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à
                if self.use_local_cache and text_hash in self.local_cache:
                    cached_data = self.local_cache[text_hash]
                    if cached_data.get("model") == model:
                        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                        cached_data["last_used_at"] = time.time()
                        batch_embeddings.append(cached_data.get("embedding"))
                        self.cache_stats['hits'] += 1
                        continue
                
                # –ü—Ä–æ–º–∞—Ö –∫–µ—à–∞
                self.cache_stats['misses'] += 1
                
                # –ù—É–∂–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å —É OpenAI
                texts_to_fetch.append(normalized_text)
                indices_to_fetch.append(idx)
                batch_embeddings.append(None)  # –ó–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—å
            
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤ –±–µ–∑ –∫–µ—à–∞
            if texts_to_fetch:
                try:
                    response = client.embeddings.create(
                        model=model,
                        input=texts_to_fetch
                    )
                    
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
                    for idx, embedding_item in enumerate(response.data):
                        original_idx = indices_to_fetch[idx]
                        embedding = embedding_item.embedding
                        batch_embeddings[original_idx] = embedding
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à
                        if self.use_local_cache:
                            text = texts_to_fetch[idx]
                            text_hash = self._get_text_hash(text)
                            current_time = time.time()
                            self.local_cache[text_hash] = {
                                "text": text[:100],
                                "model": model,
                                "embedding": embedding,
                                "created_at": current_time,
                                "last_used_at": current_time
                            }
                            self.cache_stats['saves'] += 1
                            self.cache_modified = True
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–µ—à –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ (–Ω–µ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
                    if self.use_local_cache and self.cache_stats['saves'] % 50 == 0:
                        self._save_local_cache()
                except Exception as e:
                    print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –±–∞—Ç—á–∞ {i//batch_size + 1}: {e}")
                    # –û—Å—Ç–∞–≤–ª—è–µ–º None –¥–ª—è –æ—à–∏–±–æ–∫
            
            embeddings.extend(batch_embeddings)
        
        return embeddings
    
    def clear_cache(self, older_than_days: Optional[int] = None):
        """
        –û—á–∏—â–∞–µ—Ç –∫–µ—à
        
        Args:
            older_than_days: –û—á–∏—Å—Ç–∏—Ç—å —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π (None = –æ—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ)
        """
        if older_than_days:
            # –û—á–∏—Å—Ç–∫–∞ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É
            current_time = time.time()
            threshold_time = current_time - (older_than_days * 86400)
            
            to_remove = []
            for key, entry in self.local_cache.items():
                if isinstance(entry, dict):
                    created_at = entry.get('created_at', current_time)
                    if created_at < threshold_time:
                        to_remove.append(key)
            
            for key in to_remove:
                del self.local_cache[key]
            
            self.cache_modified = True
            self._save_local_cache(force=True)
            print(f"      ‚úÖ –û—á–∏—â–µ–Ω–æ {len(to_remove)} –∑–∞–ø–∏—Å–µ–π —Å—Ç–∞—Ä—à–µ {older_than_days} –¥–Ω–µ–π")
        else:
            self.local_cache = {}
            self.cache_stats = {'hits': 0, 'misses': 0, 'saves': 0}
            self.cache_modified = True
            self._save_local_cache(force=True)
            print(f"      ‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π –∫–µ—à –æ—á–∏—â–µ–Ω")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–µ—à–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–µ—à–∞
        """
        total_requests = self.cache_stats['hits'] + self.cache_stats['misses']
        hit_rate = (self.cache_stats['hits'] / total_requests * 100) if total_requests > 0 else 0
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç –∑–∞–ø–∏—Å–µ–π
        current_time = time.time()
        ages = []
        for entry in self.local_cache.values():
            if isinstance(entry, dict) and 'created_at' in entry:
                age_days = (current_time - entry['created_at']) / 86400
                ages.append(age_days)
        
        return {
            "local_cache_size": len(self.local_cache),
            "cache_file": str(self.local_cache_file),
            "use_local_cache": self.use_local_cache,
            "use_openai_cache": self.use_openai_cache,
            "cache_hits": self.cache_stats['hits'],
            "cache_misses": self.cache_stats['misses'],
            "cache_saves": self.cache_stats['saves'],
            "hit_rate_percent": round(hit_rate, 2),
            "avg_entry_age_days": round(sum(ages) / len(ages), 1) if ages else 0,
            "oldest_entry_days": round(max(ages), 1) if ages else 0
        }
    
    def print_cache_stats(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–µ—à–∞"""
        stats = self.get_cache_stats()
        print(f"\n   üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:")
        print(f"      –†–∞–∑–º–µ—Ä –∫–µ—à–∞: {stats['local_cache_size']} –∑–∞–ø–∏—Å–µ–π")
        print(f"      –ü–æ–ø–∞–¥–∞–Ω–∏–π (hits): {stats['cache_hits']}")
        print(f"      –ü—Ä–æ–º–∞—Ö–æ–≤ (misses): {stats['cache_misses']}")
        print(f"      –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π: {stats['cache_saves']}")
        if stats['hit_rate_percent'] > 0:
            print(f"      Hit rate: {stats['hit_rate_percent']:.1f}%")
        if stats['avg_entry_age_days'] > 0:
            print(f"      –°—Ä–µ–¥–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç –∑–∞–ø–∏—Å–µ–π: {stats['avg_entry_age_days']:.1f} –¥–Ω–µ–π")

