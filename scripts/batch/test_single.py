#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ Batch API —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º
"""
import json
import tempfile
from pathlib import Path
from openai import OpenAI
import os
from dotenv import load_dotenv
import time

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env –∏–∑ –∞–∫–∫–∞—É–Ω—Ç–∞
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent.parent  # tg-analyz/
account_env_path = project_root / "data" / "accounts" / "ychukaev" / ".env"

if account_env_path.exists():
    load_dotenv(account_env_path, override=True)
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω .env –∏–∑ {account_env_path}")
else:
    print(f"‚ö† .env –Ω–µ –Ω–∞–π–¥–µ–Ω: {account_env_path}")

# –¢–∞–∫–∂–µ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
load_dotenv(project_root / ".env")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError(f"OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ {account_env_path}")

print(f"‚úì OpenAI API –∫–ª—é—á –∑–∞–≥—Ä—É–∂–µ–Ω (–¥–ª–∏–Ω–∞: {len(api_key)})")

client = OpenAI(
    api_key=api_key,
    timeout=600.0
)

# –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å - —Å–∂–∞—Ç–∏–µ –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
test_chunk = """2024-10-15
–Æ—Ä–∏–π: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞ —Å –ø—Ä–æ–µ–∫—Ç–æ–º?
–ï–≤–≥–µ–Ω–∏–π: –ü—Ä–∏–≤–µ—Ç! –í—Å—ë —Ö–æ—Ä–æ—à–æ, —Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞–¥ –∑–∞–¥–∞—á–µ–π –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É.
–Æ—Ä–∏–π: –û—Ç–ª–∏—á–Ω–æ, –∫–æ–≥–¥–∞ –ø–ª–∞–Ω–∏—Ä—É–µ–º –∑–∞–≤–µ—Ä—à–∏—Ç—å?
–ï–≤–≥–µ–Ω–∏–π: –ö –∫–æ–Ω—Ü—É –Ω–µ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã —É—Å–ø–µ—Ç—å.
–Æ—Ä–∏–π: –°—É–ø–µ—Ä, –∂–¥—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""

system_prompt = "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Å–∂–∏–º–∞—Ç—å –ø–µ—Ä–µ–ø–∏—Å–∫–∏ –¥–æ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤."

user_prompt = f"""–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –ø–µ—Ä–µ–ø–∏—Å–∫—É –ø–æ –ø—Ä–æ–µ–∫—Ç—É –§–∞—Ä–º–∞+. 

–°–æ–∂–º–∏ –¥–∏–∞–ª–æ–≥ –¥–æ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤:
- –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏–π
- –ü—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è
- –ü–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
- –î–µ–¥–ª–∞–π–Ω—ã –∏ —Å—Ä–æ–∫–∏
- –í–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –ø–æ –ø—Ä–æ–µ–∫—Ç—É

–°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏–∞–ª–æ–≥–∞ (—á–∞—Ç—ã, —É—á–∞—Å—Ç–Ω–∏–∫–∏, –¥–∞—Ç—ã), –Ω–æ —É–¥–∞–ª–∏:
- –ü–æ–≤—Ç–æ—Ä—ã –∏ —É—Ç–æ—á–Ω–µ–Ω–∏—è
- –ú–µ–ª–∫–∏–µ –¥–µ—Ç–∞–ª–∏
- –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –ø—Ä–æ—â–∞–Ω–∏—è
- –ù–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏

–í–µ—Ä–Ω–∏ —Å–∂–∞—Ç—ã–π –¥–∏–∞–ª–æ–≥, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–∞–∂–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∑–∞–¥–∞—á –∏ —Ä–µ—à–µ–Ω–∏–π.

–ò—Å—Ö–æ–¥–Ω—ã–π –¥–∏–∞–ª–æ–≥:
{test_chunk}"""

# –§–æ—Ä–º–∞—Ç –¥–ª—è responses API –≤ Batch: input –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º —Å–ª–æ–≤–∞—Ä–µ–π —Å role/content
request_data = {
    "custom_id": "test_chunk_1",
    "method": "POST",
    "url": "/v1/responses",
    "body": {
        "model": "gpt-5",
        "input": [
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": user_prompt
            }
        ],
        "reasoning": {"effort": "low"}
    }
}

# –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π JSONL —Ñ–∞–π–ª —Å –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
temp_jsonl = tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False, encoding='utf-8')
temp_jsonl.write(json.dumps(request_data, ensure_ascii=False) + '\n')
temp_jsonl.close()
jsonl_path = Path(temp_jsonl.name)

print(f"\n{'='*60}")
print(f"üì§ –¢–µ—Å—Ç–æ–≤–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ —Å –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º")
print(f"{'='*60}")
print(f"üìÑ –§–∞–π–ª: {jsonl_path}")
print(f"üìè –†–∞–∑–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞: {len(user_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
print(f"\nüì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –≤ OpenAI...")
with open(jsonl_path, 'rb') as f:
    uploaded_file = client.files.create(
        file=f,
        purpose="batch"
    )
print(f"‚úì –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.id}")

# –°–æ–∑–¥–∞–µ–º –±–∞—Ç—á
print(f"\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ –±–∞—Ç—á–∞...")
batch = client.batches.create(
    input_file_id=uploaded_file.id,
    endpoint="/v1/responses",
    completion_window="24h"
)
batch_id = batch.id
print(f"‚úì –ë–∞—Ç—á —Å–æ–∑–¥–∞–Ω: {batch_id}")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
output_dir = project_root / "results" / "farma" / "compressed_parts"
output_dir.mkdir(parents=True, exist_ok=True)
metadata_file = output_dir / "batch_metadata.json"

batch_metadata = {
    "batch_id": batch_id,
    "created_at": time.time(),
    "created_at_iso": time.strftime("%Y-%m-%d %H:%M:%S"),
    "status": "created",
    "input_file_id": uploaded_file.id,
    "test": True,
    "total_chunks": 1
}

batch_metadata_list = []
if metadata_file.exists():
    with open(metadata_file, "r", encoding="utf-8") as f:
        batch_metadata_list = json.load(f)

batch_metadata_list.append(batch_metadata)
with open(metadata_file, "w", encoding="utf-8") as f:
    json.dump(batch_metadata_list, f, ensure_ascii=False, indent=2)

print(f"üíæ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_file}")
print(f"\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–∞—Ç—á–∞ (–ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥)...")
print(f"   Batch ID: {batch_id}")
print(f"   –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –º–æ–∂–Ω–æ –∫–æ–º–∞–Ω–¥–æ–π: openai batches retrieve {batch_id}")

# –î–æ–∂–∏–¥–∞–µ–º—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–∞—Ç—á–∞
max_wait_time = 3600  # –ú–∞–∫—Å–∏–º—É–º 1 —á–∞—Å
start_time = time.time()
poll_interval = 10  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥

while True:
    elapsed = time.time() - start_time
    if elapsed > max_wait_time:
        print(f"\n‚è∞ –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è ({max_wait_time} —Å–µ–∫—É–Ω–¥)")
        break
    
    batch_status = client.batches.retrieve(batch_id)
    status = batch_status.status
    
    print(f"   [{elapsed:.0f}s] –°—Ç–∞—Ç—É—Å: {status}", end='\r')
    
    if status == "completed":
        print(f"\n‚úì –ë–∞—Ç—á –∑–∞–≤–µ—Ä—à–µ–Ω!")
        batch_metadata["status"] = "completed"
        batch_metadata["completed_at"] = time.time()
        batch_metadata["completed_at_iso"] = time.strftime("%Y-%m-%d %H:%M:%S")
        batch_metadata["processing_time_seconds"] = elapsed
        batch_metadata["output_file_id"] = batch_status.output_file_id if hasattr(batch_status, 'output_file_id') else None
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if metadata_file.exists():
            with open(metadata_file, "r", encoding="utf-8") as f:
                batch_metadata_list = json.load(f)
            for bm in batch_metadata_list:
                if bm.get("batch_id") == batch_id:
                    bm.update(batch_metadata)
                    break
            with open(metadata_file, "w", encoding="utf-8") as f:
                json.dump(batch_metadata_list, f, ensure_ascii=False, indent=2)
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if batch_status.output_file_id:
            print(f"\nüì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
            output_file = client.files.content(batch_status.output_file_id)
            output_content = output_file.read().decode('utf-8')
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for line in output_content.strip().split('\n'):
                if line.strip():
                    result = json.loads(line)
                    results.append(result)
            
            print(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if results:
                result = results[0]
                print(f"\n{'='*60}")
                print(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç:")
                print(f"{'='*60}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
                response_obj = result.get("response", {}).get("body", {})
                output_text = None
                
                if isinstance(response_obj, dict):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞
                    if "output" in response_obj:
                        output = response_obj["output"]
                        if isinstance(output, list):
                            # –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å content/text
                            chunks = []
                            for item in output:
                                if isinstance(item, dict):
                                    if "content" in item:
                                        for content_item in item.get("content", []):
                                            if isinstance(content_item, dict) and "text" in content_item:
                                                chunks.append(content_item["text"])
                                    elif "text" in item:
                                        chunks.append(item["text"])
                            output_text = '\n'.join(chunks).strip()
                        elif isinstance(output, str):
                            output_text = output
                    elif "output_text" in response_obj:
                        output_text = response_obj["output_text"]
                    elif "text" in response_obj:
                        output_text = response_obj["text"]
                
                if output_text:
                    print(output_text)
                else:
                    print("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞")
                    print(f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç: {json.dumps(response_obj, ensure_ascii=False, indent=2)}")
        
        break
    elif status == "failed" or status == "expired" or status == "cancelled":
        print(f"\n‚ùå –ë–∞—Ç—á –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º: {status}")
        batch_metadata["status"] = status
        batch_metadata[f"{status}_at"] = time.time()
        batch_metadata[f"{status}_at_iso"] = time.strftime("%Y-%m-%d %H:%M:%S")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if metadata_file.exists():
            with open(metadata_file, "r", encoding="utf-8") as f:
                batch_metadata_list = json.load(f)
            for bm in batch_metadata_list:
                if bm.get("batch_id") == batch_id:
                    bm.update(batch_metadata)
                    break
            with open(metadata_file, "w", encoding="utf-8") as f:
                json.dump(batch_metadata_list, f, ensure_ascii=False, indent=2)
        
        if hasattr(batch_status, 'errors'):
            print(f"–û—à–∏–±–∫–∏: {batch_status.errors}")
        break
    else:
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        batch_metadata["status"] = status
        if metadata_file.exists():
            with open(metadata_file, "r", encoding="utf-8") as f:
                batch_metadata_list = json.load(f)
            for bm in batch_metadata_list:
                if bm.get("batch_id") == batch_id:
                    bm.update(batch_metadata)
                    break
            with open(metadata_file, "w", encoding="utf-8") as f:
                json.dump(batch_metadata_list, f, ensure_ascii=False, indent=2)
    
    time.sleep(poll_interval)

# –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
jsonl_path.unlink()
print(f"\n‚úì –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω")

