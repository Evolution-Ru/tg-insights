#!/usr/bin/env python3
"""
–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–∞—Ç—á–∞
"""
import json
import os
from dotenv import load_dotenv
from pathlib import Path
from openai import OpenAI

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent.parent  # tg-analyz/
account_env_path = project_root / "data" / "accounts" / "ychukaev" / ".env"

if account_env_path.exists():
    load_dotenv(account_env_path, override=True)

load_dotenv(project_root / ".env")

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")

client = OpenAI(api_key=api_key, timeout=600.0)

# ID –±–∞—Ç—á–∞ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏)
import sys
batch_id = sys.argv[1] if len(sys.argv) > 1 else "batch_691064ceb7088190a65faf2142f5458d"

print(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–∞—Ç—á–∞ {batch_id}...\n")

# –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –±–∞—Ç—á–∞
batch_detail = client.batches.retrieve(batch_id)
print(f"–°—Ç–∞—Ç—É—Å: {batch_detail.status}")
print(f"–ó–∞–ø—Ä–æ—Å–æ–≤: {batch_detail.request_counts}")

if batch_detail.status == "completed" and batch_detail.output_file_id:
    print(f"\nüì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ output —Ñ–∞–π–ª–∞: {batch_detail.output_file_id}")
    output_file = client.files.content(batch_detail.output_file_id)
    output_content = output_file.read().decode('utf-8')
    
    # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = []
    for line in output_content.strip().split('\n'):
        if line.strip():
            result = json.loads(line)
            results.append(result)
    
    print(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if results:
        print("üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
        print(json.dumps(results[0], ensure_ascii=False, indent=2)[:1000])
        print("...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        response_body = results[0].get('response', {}).get('body', {})
        print(f"\nüìù –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        
        output_text = None
        if 'output_text' in response_body:
            output_text = response_body['output_text']
        elif 'output' in response_body:
            output = response_body['output']
            if isinstance(output, str):
                output_text = output
            elif isinstance(output, list):
                chunks = []
                for item in output:
                    if isinstance(item, dict):
                        if 'text' in item:
                            chunks.append(item['text'])
                        elif 'content' in item:
                            for c in item.get('content', []):
                                if isinstance(c, dict) and 'text' in c:
                                    chunks.append(c['text'])
                output_text = '\n'.join(chunks)
        
        if output_text:
            print(f"‚úì –¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω ({len(output_text)} —Å–∏–º–≤–æ–ª–æ–≤):")
            print(output_text[:500])
            print("...")
        else:
            print("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç")
            print(f"–ü–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ response.body: {json.dumps(response_body, ensure_ascii=False, indent=2)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    output_file_path = project_root / "results" / "farma" / "compressed_parts" / f"batch_{batch_id}_results.json"
    output_file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file_path}")

