"""
–†–∞–±–æ—Ç–∞ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
"""
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from ..utils.gpt5_client import get_openai_client


def get_embedding(text: str, model: str = "text-embedding-3-small", client=None) -> Optional[List[float]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ drill-down.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        client: OpenAI –∫–ª–∏–µ–Ω—Ç (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª (—ç–º–±–µ–¥–¥–∏–Ω–≥) –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if client is None:
        client = get_openai_client()
    
    try:
        response = client.embeddings.create(
            model=model,
            input=text[:8000]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è embeddings API
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"      ‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        return None


def cosine_similarity_embedding(vec1: List[float], vec2: List[float]) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
    
    Args:
        vec1: –ü–µ—Ä–≤—ã–π –≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        vec2: –í—Ç–æ—Ä–æ–π –≤–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
    
    Returns:
        –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (–æ—Ç -1 –¥–æ 1)
    """
    try:
        import numpy as np
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    except ImportError:
        # Fallback –±–µ–∑ numpy
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = sum(a * a for a in vec1) ** 0.5
        norm2 = sum(b * b for b in vec2) ** 0.5
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return dot_product / (norm1 * norm2)


def save_embeddings_for_level(
    level: str, 
    items: List[Dict[str, Any]], 
    output_dir: Path,
    client=None,
    cache_hours: float = 3.0
):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–µ—à, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —Å–æ–∑–¥–∞–Ω –º–µ–Ω–µ–µ cache_hours —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥.
    
    Args:
        level: 'raw_messages', 'compressed_chunks', 'summaries', 'tasks', 'projects'
        items: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏ 'text', 'id', 'metadata' –∏ —Ç.–¥.
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        client: OpenAI –∫–ª–∏–µ–Ω—Ç (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
        cache_hours: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞ –≤ —á–∞—Å–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3 —á–∞—Å–∞)
    """
    if client is None:
        client = get_openai_client()
    
    embeddings_file = output_dir / f"embeddings_{level}.json"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à: –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —Å–æ–∑–¥–∞–Ω –º–µ–Ω–µ–µ cache_hours —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if embeddings_file.exists():
        file_age_hours = (time.time() - embeddings_file.stat().st_mtime) / 3600
        if file_age_hours < cache_hours:
            print(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —É—Ä–æ–≤–Ω—è '{level}' (–≤–æ–∑—Ä–∞—Å—Ç: {file_age_hours:.1f} —á–∞—Å–æ–≤)")
            print(f"   üíæ –§–∞–π–ª: {embeddings_file}")
            return
    
    embeddings_data = []
    
    print(f"   üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —É—Ä–æ–≤–Ω—è '{level}' ({len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)...")
    
    for i, item in enumerate(items, 1):
        text = item.get('text', '')
        if not text:
            continue
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
        embedding = get_embedding(text, client=client)
        if embedding:
            embeddings_data.append({
                'id': item.get('id', i),
                'text': text[:500],  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞—á–∞–ª–æ –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏
                'embedding': embedding,
                'metadata': item.get('metadata', {})
            })
            if i % 10 == 0:
                print(f"      –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(items)}...", end='\r', flush=True)
    
    print(f"      ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(embeddings_data)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    if embeddings_data:
        with open(embeddings_file, "w", encoding="utf-8") as f:
            json.dump(embeddings_data, f, ensure_ascii=False, indent=2)
        print(f"   üíæ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {embeddings_file}")


def find_relevant_sources_by_embedding(
    query_text: str,
    source_level: str,
    output_dir: Path,
    top_k: int = 5,
    similarity_threshold: float = 0.7,
    client=None
) -> List[Dict[str, Any]]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è drill-down: –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∑–∞–¥–∞—á–∏/–ø—Ä–æ–µ–∫—Ç–∞.
    
    Args:
        query_text: —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏)
        source_level: —É—Ä–æ–≤–µ–Ω—å –∏—Å—Ç–æ—á–Ω–∏–∫–∞ ('raw_messages', 'compressed_chunks', 'summaries')
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ñ–∞–π–ª–∞–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        similarity_threshold: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
        client: OpenAI –∫–ª–∏–µ–Ω—Ç (–µ—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ö–æ–∂–µ—Å—Ç–∏
    """
    if client is None:
        client = get_openai_client()
    
    embeddings_file = output_dir / f"embeddings_{source_level}.json"
    
    if not embeddings_file.exists():
        print(f"   ‚ö† –§–∞–π–ª —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {embeddings_file}")
        return []
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    with open(embeddings_file, "r", encoding="utf-8") as f:
        source_embeddings = json.load(f)
    
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
    query_embedding = get_embedding(query_text, client=client)
    if not query_embedding:
        return []
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å —Å–æ –≤—Å–µ–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    similarities = []
    for source in source_embeddings:
        similarity = cosine_similarity_embedding(query_embedding, source['embedding'])
        if similarity >= similarity_threshold:
            similarities.append({
                'id': source['id'],
                'text': source['text'],
                'similarity': similarity,
                'metadata': source.get('metadata', {})
            })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º top_k
    similarities.sort(key=lambda x: x['similarity'], reverse=True)
    return similarities[:top_k]

