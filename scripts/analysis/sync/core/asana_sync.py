#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞—á –º–µ–∂–¥—É Telegram –∏ Asana
–î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
"""
import json
import sys
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
_script_dir = Path(__file__).resolve().parent
_project_root = _script_dir.parent.parent.parent
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))

from scripts.analysis.utils.gpt5_client import get_openai_client
from scripts.analysis.embeddings.embeddings import get_embedding, cosine_similarity_embedding
from ..utils.matchers.time_window import TimeWindowMatcher
from ..utils.cache.embedding_cache import EmbeddingCache
from ..utils.extractors.asana_summarizer import AsanaTaskSummarizer
from ..utils.extractors.context_extractor import AsanaContextExtractor, normalize_text
from ..utils.transformers.task_transformer import enrich_asana_task_with_telegram, create_asana_task_from_telegram
from ..utils.reporting.report_generator import analyze_coverage, generate_sync_report
from ..utils.matchers.similarity_calculator import calculate_similarity_gpt5
from ..utils.loaders.data_loader import load_telegram_tasks, load_telegram_projects


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Asana
ASANA_WORKSPACE_GID = "624391999090674"
ASANA_USER_GID = "1169547205416171"
ASANA_PROJECT_GID = "1210655252186716"  # –§–∞—Ä–º–∞+
ASANA_ESTIMATED_TIME_FIELD_GID = "1204112099563346"


class AsanaSync:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞—á –º–µ–∂–¥—É Telegram –∏ Asana"""
    
    def __init__(self, mcp_client=None, openai_client=None, use_time_windows: bool = True, use_embedding_cache: bool = True, use_task_summarization: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            mcp_client: –ö–ª–∏–µ–Ω—Ç MCP –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Asana API
            openai_client: –ö–ª–∏–µ–Ω—Ç OpenAI –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            use_time_windows: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∑–∞–¥–∞—á
            use_embedding_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–µ—à —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            use_task_summarization: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ GPT-5
        """
        self.mcp_client = mcp_client
        self.openai_client = openai_client or get_openai_client()
        self.workspace_gid = ASANA_WORKSPACE_GID
        self.project_gid = ASANA_PROJECT_GID
        self.use_time_windows = use_time_windows
        self.time_window_matcher = TimeWindowMatcher() if use_time_windows else None
        self.embedding_cache = EmbeddingCache(use_local_cache=use_embedding_cache) if use_embedding_cache else None
        self.use_task_summarization = use_task_summarization
        self.task_summarizer = AsanaTaskSummarizer(client=self.openai_client) if use_task_summarization else None
        # –ö–µ—à —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
        self._summarized_tasks_cache = {}
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        self.context_extractor = AsanaContextExtractor(
            task_summarizer=self.task_summarizer,
            summarized_tasks_cache=self._summarized_tasks_cache
        )
        
    def load_telegram_tasks(self, tasks_file: Path) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Telegram –∞–Ω–∞–ª–∏–∑–∞ (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ data_loader)"""
        return load_telegram_tasks(tasks_file)
    
    def load_telegram_projects(self, projects_file: Path) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ Telegram –∞–Ω–∞–ª–∏–∑–∞ (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ data_loader)"""
        return load_telegram_projects(projects_file)
    
    def normalize_text(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ context_extractor)"""
        return normalize_text(text)
    
    def extract_asana_task_context(self, asana_task: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –≤—ã–∂–∏–º–∫—É –∏–∑ –∑–∞–¥–∞—á–∏ Asana (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ context_extractor)
        """
        return self.context_extractor.extract_asana_task_context(asana_task)
    
    def create_asana_task_summary(self, asana_task: Dict[str, Any], use_gpt5: bool = False) -> str:
        """–°–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –∑–∞–¥–∞—á–∏ Asana (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ context_extractor)"""
        return self.context_extractor.create_asana_task_summary(
            asana_task, 
            openai_client=self.openai_client if use_gpt5 else None,
            use_gpt5=use_gpt5
        )
    
    def calculate_similarity(self, text1: str, text2: str, verbose: bool = False) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ GPT-5 (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ similarity_calculator)"""
        return calculate_similarity_gpt5(text1, text2, self.openai_client, verbose)
    
    def find_matching_tasks(
        self, 
        telegram_tasks: List[Dict[str, Any]], 
        asana_tasks: List[Dict[str, Any]],
        similarity_threshold: float = 0.7,
        verbose: bool = True,
        max_asana_tasks: Optional[int] = None,
        use_embeddings: bool = True,
        use_gpt5_verification: bool = False,  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ GPT-5 (–¥–æ—Ä–æ–≥–æ!)
        low_threshold: float = 0.65,  # –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        use_two_stage_matching: bool = True  # –î–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ + GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞
    ) -> Dict[str, List[Tuple[Dict, Dict, float]]]:
        """
        –ù–∞–π—Ç–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ –∏–∑ Telegram –∏ Asana
        
        Args:
            telegram_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Telegram
            asana_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Asana
            similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0-1.0) - –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ–±—ã—á–Ω–æ 0.7-0.8
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
            max_asana_tasks: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á Asana –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∞)
            use_embeddings: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
            use_gpt5_verification: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPT-5 –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–¥–æ—Ä–æ–≥–æ!)
            low_threshold: –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.65)
            use_two_stage_matching: –î–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –µ—Å–ª–∏ score –º–µ–∂–¥—É low_threshold –∏ similarity_threshold, 
                                   –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –Ω–∞ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
        
        Returns:
            Dict —Å –∫–ª—é—á–∞–º–∏:
            - 'matches': —Å–ø–∏—Å–æ–∫ (telegram_task, asana_task, similarity_score)
            - 'telegram_only': –∑–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Telegram
            - 'asana_only': –∑–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Asana
        """
        matches = []
        telegram_matched = set()
        asana_matched = set()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á Asana –¥–ª—è —Ç–µ—Å—Ç–∞
        if max_asana_tasks:
            asana_tasks = asana_tasks[:max_asana_tasks]
            if verbose:
                print(f"   ‚ö†Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å {max_asana_tasks} –∑–∞–¥–∞—á–∞–º–∏ Asana")
        
        if verbose:
            print(f"   üìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(telegram_tasks)} Telegram √ó {len(asana_tasks)} Asana")
        
        # –®–∞–≥ 1: –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á Asana (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏)
        quota_exceeded_during_embeddings = False  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
        if use_embeddings:
            if verbose:
                print(f"\n   üî¢ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(asana_tasks)} –∑–∞–¥–∞—á Asana...")
            
            asana_embeddings = []
            asana_texts = []
            asana_contexts = []  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –≤—ã–∂–∏–º–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
            for idx, asana_task in enumerate(asana_tasks):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –≤—ã–∂–∏–º–∫—É
                context = self.extract_asana_task_context(asana_task)
                asana_contexts.append(context)
                
                # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é (–ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è)
                asana_text = context.get('embedding_text', context['full_text'])[:8000]
                asana_texts.append(asana_text)
                
                if verbose and (idx + 1) % 20 == 0:
                    print(f"      üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1}/{len(asana_tasks)}...", end='\r', flush=True)
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏
            try:
                if verbose:
                    print(f"      üîÑ –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ API...")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –≤–∞–ª–∏–¥–Ω—ã (–Ω–µ –ø—É—Å—Ç—ã–µ)
                # –î–ª—è –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∑–∞–≥–ª—É—à–∫—É
                processed_texts = []
                for text in asana_texts:
                    if text and text.strip():
                        processed_texts.append(text[:8000])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                    else:
                        # –î–ª—è –ø—É—Å—Ç—ã—Ö –∑–∞–¥–∞—á –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∑–∞–≥–ª—É—à–∫—É
                        processed_texts.append("empty")
                
                # OpenAI embeddings API –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–∞—Ç—á–∏ –¥–æ 2048 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                batch_size = 100
                for i in range(0, len(processed_texts), batch_size):
                    batch_texts = processed_texts[i:i+batch_size]
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ API
                    batch_texts_filtered = []
                    batch_indices = []  # –ò–Ω–¥–µ–∫—Å—ã –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –≤ –±–∞—Ç—á–µ
                    for j, text in enumerate(batch_texts):
                        if text and text.strip() and text != "empty":
                            batch_texts_filtered.append(text)
                            batch_indices.append(j)
                    
                    if not batch_texts_filtered:
                        # –ï—Å–ª–∏ –≤–µ—Å—å –±–∞—Ç—á –ø—É—Å—Ç–æ–π, –¥–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                        for _ in batch_texts:
                            asana_embeddings.append([0.0] * 1536)  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å text-embedding-3-small
                    else:
                        try:
                            batch_response = self.openai_client.embeddings.create(
                                model="text-embedding-3-small",
                                input=batch_texts_filtered
                            )
                            batch_embeddings = [item.embedding for item in batch_response.data]
                            
                            # –ó–∞–ø–æ–ª–Ω—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å —É—á–µ—Ç–æ–º –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
                            embedding_idx = 0
                            for j in range(len(batch_texts)):
                                if j in batch_indices:
                                    asana_embeddings.append(batch_embeddings[embedding_idx])
                                    embedding_idx += 1
                                else:
                                    # –î–ª—è –ø—É—Å—Ç—ã—Ö –∑–∞–¥–∞—á —Å–æ–∑–¥–∞–µ–º –Ω—É–ª–µ–≤–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥
                                    asana_embeddings.append([0.0] * 1536)
                        except Exception as e:
                            error_str = str(e)
                            error_type = type(e).__name__
                            # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
                            if verbose:
                                print(f"\n      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–±–∞—Ç—á {i//batch_size + 1}):")
                                print(f"         –¢–∏–ø: {error_type}")
                                print(f"         –°–æ–æ–±—â–µ–Ω–∏–µ: {error_str[:200]}")
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –∫–≤–æ—Ç—ã
                            if '429' in error_str or 'insufficient_quota' in error_str or 'quota' in error_str.lower() or 'rate_limit' in error_str.lower():
                                if verbose:
                                    print(f"\n      ‚ùå –ü–†–ï–í–´–®–ï–ù–ê –ö–í–û–¢–ê OpenAI! –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.")
                                    print(f"      üí° –†–µ—à–µ–Ω–∏–µ: –ø–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å OpenAI –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è")
                                use_embeddings = False
                                quota_exceeded_during_embeddings = True
                                break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
                            else:
                                if verbose:
                                    print(f"      ‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞, –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–∞–≤–µ—Ä—Ö")
                                raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –¥—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ –Ω–∞–≤–µ—Ä—Ö
                    
                    if quota_exceeded_during_embeddings:
                        break
                    
                    if verbose:
                        print(f"      ‚úÖ –ë–∞—Ç—á {i//batch_size + 1}/{(len(processed_texts)-1)//batch_size + 1} –≥–æ—Ç–æ–≤", end='\r', flush=True)
                
                if verbose and not quota_exceeded_during_embeddings:
                    print(f"\n      ‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è Asana –≥–æ—Ç–æ–≤—ã ({len(asana_embeddings)} —à—Ç.)")
            except Exception as e:
                error_str = str(e)
                error_type = type(e).__name__
                # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
                if verbose:
                    print(f"\n      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å):")
                    print(f"         –¢–∏–ø: {error_type}")
                    print(f"         –°–æ–æ–±—â–µ–Ω–∏–µ: {error_str[:300]}")
                    import traceback
                    print(f"         Traceback: {traceback.format_exc()[:500]}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –∫–≤–æ—Ç—ã (–µ—Å–ª–∏ –æ—à–∏–±–∫–∞ –Ω–µ –±—ã–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞)
                if '429' in error_str or 'insufficient_quota' in error_str or 'quota' in error_str.lower() or 'rate_limit' in error_str.lower():
                    if verbose:
                        print(f"\n      ‚ùå –ü–†–ï–í–´–®–ï–ù–ê –ö–í–û–¢–ê OpenAI! –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.")
                        print(f"      üí° –†–µ—à–µ–Ω–∏–µ: –ø–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å OpenAI –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è")
                    use_embeddings = False
                    quota_exceeded_during_embeddings = True
                else:
                    if verbose:
                        print(f"\n      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ GPT-5")
                        import traceback
                        traceback.print_exc()
                    use_embeddings = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –æ—à–∏–±–∫–∞ –∫–≤–æ—Ç—ã
        quota_exceeded = False
        if not use_embeddings:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –æ—à–∏–±–∫–∞ –∫–≤–æ—Ç—ã –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            if 'quota_exceeded_during_embeddings' in locals() and quota_exceeded_during_embeddings:
                quota_exceeded = True
            else:
                # –ü—Ä–æ–±—É–µ–º –æ–¥–∏–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ GPT-5 –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–≤–æ—Ç—ã
                try:
                    test_response = self.openai_client.responses.create(
                        model="gpt-5",
                        input=[{"role": "user", "content": "test"}],
                        reasoning={"effort": "low"}
                    )
                except Exception as e:
                    error_str = str(e)
                    if '429' in error_str or 'insufficient_quota' in error_str or 'quota' in error_str.lower():
                        quota_exceeded = True
                        if verbose:
                            print(f"\n   ‚ùå –ü–†–ï–í–´–®–ï–ù–ê –ö–í–û–¢–ê OpenAI! –†–∞–±–æ—Ç–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞.")
                            print(f"   üí° –†–µ—à–µ–Ω–∏–µ: –ø–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å OpenAI")
                            print(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π (–±–µ–∑ API)")
        
        # –®–∞–≥ 2: –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É –∏–∑ Telegram —Å –∑–∞–¥–∞—á–∞–º–∏ Asana
        if verbose:
            print(f"\n   üîç –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π...")
            if quota_exceeded:
                print(f"      ‚ö†Ô∏è  –†–µ–∂–∏–º –±–µ–∑ API: —Ç–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π")
            elif use_embeddings:
                cost_info = "üí∞ –î–µ—à–µ–≤–æ (—Ç–æ–ª—å–∫–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏)"
                if use_gpt5_verification:
                    cost_info += " + GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ (–¥–æ—Ä–æ–∂–µ)"
                print(f"      ‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ {cost_info}")
            else:
                print(f"      üêå –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-5 –¥–ª—è –≤—Å–µ—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π (–º–µ–¥–ª–µ–Ω–Ω–æ –∏ –¥–æ—Ä–æ–≥–æ)")
        
        for tg_idx, tg_task in enumerate(telegram_tasks, 1):
            tg_title = tg_task.get('title', '')
            tg_desc = tg_task.get('description', '')
            tg_context = tg_task.get('context', '')
            # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é:
            # title + description + –ø–µ—Ä–≤—ã–µ 1500 —Å–∏–º–≤–æ–ª–æ–≤ context (–≤–∞–∂–Ω–µ–µ –Ω–∞—á–∞–ª–æ)
            # –≠—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ, —Ç–∞–∫ –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å—Ä–µ–¥–Ω—è—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            tg_context_compact = tg_context[:1500] if tg_context else ''
            tg_text = f"{tg_title} {tg_desc} {tg_context_compact}".strip()[:8000]
            
            if verbose:
                print(f"\n   [{tg_idx}/{len(telegram_tasks)}] üì± Telegram: {tg_title[:60]}...")
            
            best_match = None
            best_score = 0.0
            best_asana_idx = -1
            
            # –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: —Ç–æ—á–Ω–æ–µ/—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π (–±—ã—Å—Ç—Ä–æ –∏ —Ç–æ—á–Ω–æ!)
            tg_title_normalized = self.normalize_text(tg_title)
            exact_match_found = False
            
            for idx, asana_task in enumerate(asana_tasks):
                if idx in asana_matched:
                    continue
                
                asana_name = asana_task.get('name', '')
                asana_name_normalized = self.normalize_text(asana_name)
                
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π
                if tg_title_normalized == asana_name_normalized:
                    best_match = asana_task
                    best_score = 1.0
                    best_asana_idx = idx
                    exact_match_found = True
                    if verbose:
                        print(f"      ‚úÖ –¢–û–ß–ù–û–ï –°–û–í–ü–ê–î–ï–ù–ò–ï –ù–ê–ó–í–ê–ù–ò–ô! Score: 1.00 ‚Üí {asana_name[:50]}")
                    break
                
                # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: –æ–¥–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥—Ä—É–≥–æ–µ
                if tg_title_normalized in asana_name_normalized or asana_name_normalized in tg_title_normalized:
                    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                    shorter = min(len(tg_title_normalized), len(asana_name_normalized))
                    longer = max(len(tg_title_normalized), len(asana_name_normalized))
                    if shorter > 0:
                        partial_score = shorter / longer
                        if partial_score > 0.7:  # –ú–∏–Ω–∏–º—É–º 70% —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                            if partial_score > best_score:
                                best_match = asana_task
                                best_score = partial_score
                                best_asana_idx = idx
                                exact_match_found = True
                                if verbose:
                                    print(f"      ‚úÖ –ß–ê–°–¢–ò–ß–ù–û–ï –°–û–í–ü–ê–î–ï–ù–ò–ï –ù–ê–ó–í–ê–ù–ò–ô! Score: {partial_score:.2f} ‚Üí {asana_name[:50]}")
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            if exact_match_found and best_score >= similarity_threshold:
                matches.append((tg_task, best_match, best_score))
                telegram_matched.add(tg_idx - 1)
                asana_matched.add(best_asana_idx)
                if verbose:
                    print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ! Score: {best_score:.2f} ‚Üí {best_match.get('name', '')[:50]}")
                continue
            
            # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
            if quota_exceeded:
                if verbose and not exact_match_found:
                    print(f"      ‚ö†Ô∏è  –ö–≤–æ—Ç–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∞, —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π)")
                continue
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            if use_embeddings:
                # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–¥–µ—à–µ–≤–æ!)
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–¥–∞—á–∏ Telegram
                    tg_embedding = get_embedding(tg_text, client=self.openai_client)
                    if not tg_embedding:
                        if verbose:
                            print(f"      ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å —Å–æ –≤—Å–µ–º–∏ –∑–∞–¥–∞—á–∞–º–∏ Asana
                    candidates = []
                    for idx, asana_embedding in enumerate(asana_embeddings):
                        if idx in asana_matched:
                            continue
                        
                        similarity = cosine_similarity_embedding(tg_embedding, asana_embedding)
                        candidates.append((idx, similarity))
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä–µ–º –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
                    candidates.sort(key=lambda x: x[1], reverse=True)
                    
                    if candidates:
                        candidate_idx, candidate_score = candidates[0]
                        candidate_task = asana_tasks[candidate_idx]
                        
                        # –ï—Å–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–∞–ª –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —á–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                        if candidate_score > best_score:
                            best_asana_idx = candidate_idx
                            best_score = candidate_score
                            best_match = candidate_task
                            
                            if verbose:
                                print(f"      üî¢ –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {best_score:.3f} ‚Üí {best_match.get('name', '')[:50]}")
                        elif verbose and best_score > 0:
                            print(f"      üî¢ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏: {candidate_score:.3f} (—É–∂–µ –µ—Å—Ç—å –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {best_score:.3f})")
                        
                        # –î–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: –µ—Å–ª–∏ score –º–µ–∂–¥—É low_threshold –∏ similarity_threshold
                        needs_gpt5_check = False
                        if use_two_stage_matching and low_threshold <= best_score < similarity_threshold:
                            needs_gpt5_check = True
                            if verbose:
                                print(f"         ‚ö†Ô∏è  –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (score {best_score:.3f} < –ø–æ—Ä–æ–≥–∞ {similarity_threshold}), —Ç—Ä–µ–±—É–µ—Ç—Å—è GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞")
                        
                        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ GPT-5
                        # –î–ª—è GPT-5 –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                        if best_match and ((use_gpt5_verification and best_score >= similarity_threshold) or needs_gpt5_check):
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ context –¥–ª—è GPT-5
                            best_match_context = self.extract_asana_task_context(best_match)
                            asana_text_full = best_match_context['full_text']
                            
                            # –î–ª—è Telegram —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π context –ø—Ä–∏ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–µ
                            tg_text_full = f"{tg_title} {tg_desc} {tg_context}".strip()[:8000]
                            
                            try:
                                gpt5_score = self.calculate_similarity(tg_text_full, asana_text_full, verbose=verbose)
                                if verbose:
                                    if needs_gpt5_check:
                                        print(f"         üîç GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {best_score:.3f} ‚Üí {gpt5_score:.2f}")
                                    else:
                                        print(f"         üîç GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞: {best_score:.3f} ‚Üí {gpt5_score:.2f}")
                                
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-5 –æ—Ü–µ–Ω–∫—É –µ—Å–ª–∏ –æ–Ω–∞ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
                                if gpt5_score >= similarity_threshold:
                                    best_score = gpt5_score
                                    if verbose and needs_gpt5_check:
                                        print(f"         ‚úÖ GPT-5 –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ!")
                                else:
                                    # GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, –Ω–æ –µ—Å–ª–∏ –±—ã–ª–æ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π, –æ—Å—Ç–∞–≤–ª—è–µ–º –µ–≥–æ
                                    if exact_match_found:
                                        if verbose:
                                            print(f"         ‚ö†Ô∏è  GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π")
                                    else:
                                        # GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª –∏ –Ω–µ –±—ã–ª–æ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
                                        if verbose and needs_gpt5_check:
                                            print(f"         ‚ùå GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ")
                                        best_match = None
                                        best_score = 0.0
                                        best_asana_idx = -1
                            except Exception as e:
                                if verbose:
                                    print(f"         ‚ö†Ô∏è  –û—à–∏–±–∫–∞ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
                                # –ï—Å–ª–∏ –±—ã–ª–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∏ GPT-5 —É–ø–∞–ª, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
                                if needs_gpt5_check:
                                    best_match = None
                                    best_score = 0.0
                                    best_asana_idx = -1
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
                    if best_score < similarity_threshold:
                        best_match = None
                        best_score = 0.0
                        best_asana_idx = -1
                
                except Exception as e:
                    if verbose:
                        print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {e}, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ GPT-5")
                    use_embeddings = False
            
            # Fallback: –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä —á–µ—Ä–µ–∑ GPT-5 (–µ—Å–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –∏ –∫–≤–æ—Ç–∞ –Ω–µ –ø—Ä–µ–≤—ã—à–µ–Ω–∞)
            comparisons_done = 0  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
            quota_error_count = 0
            if not use_embeddings and not quota_exceeded:
                # –ï—Å–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º GPT-5 –¥–ª—è –≤—Å–µ—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
                comparisons_done = 0
                quota_error_count = 0
                for idx, asana_task in enumerate(asana_tasks):
                    if idx in asana_matched:
                        continue
                    
                    asana_name = asana_task.get('name', '')
                    asana_notes = asana_task.get('notes', '') or ''
                    # –î–ª—è GPT-5 –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ context
                    asana_context = self.extract_asana_task_context(asana_task)
                    asana_text_full = asana_context['full_text']
                    
                    comparisons_done += 1
                    if verbose and comparisons_done % 10 == 0:
                        print(f"      üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ {comparisons_done}/{len(asana_tasks)}...", end='\r', flush=True)
                    
                    try:
                        # –î–ª—è Telegram –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π context –ø—Ä–∏ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–µ
                        tg_text_full = f"{tg_title} {tg_desc} {tg_context}".strip()[:8000]
                        score = self.calculate_similarity(tg_text_full, asana_text_full, verbose=verbose)
                        
                        if score > best_score and score >= similarity_threshold:
                            best_score = score
                            best_match = asana_task
                            best_asana_idx = idx
                        quota_error_count = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
                    except Exception as e:
                        error_str = str(e)
                        if '429' in error_str or 'insufficient_quota' in error_str or 'quota' in error_str.lower():
                            quota_error_count += 1
                            if quota_error_count >= 3:  # –ï—Å–ª–∏ 3 –æ—à–∏–±–∫–∏ –ø–æ–¥—Ä—è–¥ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
                                if verbose:
                                    print(f"\n      ‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ OpenAI! –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
                                    print(f"      ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π")
                                quota_exceeded = True
                                break
                        if verbose and quota_error_count == 0:
                            print(f"\n      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –∑–∞–¥–∞—á–µ–π '{asana_name[:40]}': {e}")
                        continue
            
            if best_match:
                matches.append((tg_task, best_match, best_score))
                telegram_matched.add(tg_idx - 1)  # tg_idx –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 1, –∏–Ω–¥–µ–∫—Å —Å 0
                asana_matched.add(best_asana_idx)
                if verbose:
                    print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ! Score: {best_score:.2f} ‚Üí {best_match.get('name', '')[:50]}")
            else:
                if verbose:
                    print(f"      ‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ—Ä–æ–≥: {similarity_threshold})")
        
        # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Telegram
        telegram_only = [
            tg_task for idx, tg_task in enumerate(telegram_tasks)
            if idx not in telegram_matched
        ]
        
        # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Asana
        asana_only = [
            asana_task for idx, asana_task in enumerate(asana_tasks)
            if idx not in asana_matched
        ]
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è: —á—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ Asana –∏–∑ –∑–∞–¥–∞—á Telegram
        coverage_analysis = self._analyze_coverage(matches, telegram_tasks, asana_tasks)
        
        return {
            'matches': matches,
            'telegram_only': telegram_only,
            'asana_only': asana_only,
            'coverage': coverage_analysis
        }
    
    def find_matching_tasks_v2(
        self,
        telegram_tasks: List[Dict[str, Any]],
        asana_tasks: List[Dict[str, Any]],
        similarity_threshold: float = 0.75,
        verbose: bool = True,
        use_embeddings: bool = True,
        use_gpt5_verification: bool = False,
        low_threshold: float = 0.65,
        use_two_stage_matching: bool = True
    ) -> Dict[str, List[Tuple[Dict, Dict, float]]]:
        """
        –ù–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–∏—Å–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –∏ –∫–µ—à–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        0. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á Asana —á–µ—Ä–µ–∑ GPT-5 Batch API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        1. –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö Telegram –∑–∞–¥–∞—á –±–∞—Ç—á–∞–º–∏
        2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω –¥–ª—è –∫–∞–∂–¥–æ–π Telegram –∑–∞–¥–∞—á–∏
        3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á Asana –ø–æ –æ–∫–Ω–∞–º
        4. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (—Å –∫–µ—à–µ–º, –∏—Å–ø–æ–ª—å–∑—É—è —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏)
        5. GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        
        Args:
            telegram_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Telegram
            asana_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Asana
            similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0-1.0)
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
            use_embeddings: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            use_gpt5_verification: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPT-5 –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            low_threshold: –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            use_two_stage_matching: –î–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        Returns:
            Dict —Å –∫–ª—é—á–∞–º–∏: 'matches', 'telegram_only', 'asana_only', 'coverage'
        """
        matches = []
        telegram_matched = set()
        asana_matched = set()
        
        if verbose:
            print(f"   üìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(telegram_tasks)} Telegram √ó {len(asana_tasks)} Asana")
            if self.use_time_windows:
                print(f"   ‚è∞ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            if self.embedding_cache:
                cache_stats = self.embedding_cache.get_cache_stats()
                print(f"   üíæ –ö–µ—à —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {cache_stats['local_cache_size']} –∑–∞–ø–∏—Å–µ–π")
            if self.use_task_summarization and self.task_summarizer:
                print(f"   üìù –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á —á–µ—Ä–µ–∑ GPT-5 Batch API")
        
        # –®–∞–≥ 0: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á Asana —á–µ—Ä–µ–∑ Batch API (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
        if self.use_task_summarization and self.task_summarizer:
            if verbose:
                print(f"\n   üìù –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è {len(asana_tasks)} –∑–∞–¥–∞—á Asana —á–µ—Ä–µ–∑ Batch API...")
            
            try:
                summarized_tasks = self.task_summarizer.summarize_tasks_batch(
                    asana_tasks,
                    verbose=verbose
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
                self._summarized_tasks_cache.update(summarized_tasks)
                
                if verbose:
                    print(f"   ‚úÖ –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(summarized_tasks)} –∑–∞–¥–∞—á")
            except Exception as e:
                if verbose:
                    print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}")
                    print(f"   üí° –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        
        # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö Telegram –∑–∞–¥–∞—á –±–∞—Ç—á–∞–º–∏ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞—Ç—Ä–∞—Ç)
        telegram_embeddings_map = {}
        if use_embeddings:
            if verbose:
                print(f"\n   üî¢ –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(telegram_tasks)} Telegram –∑–∞–¥–∞—á (–±–∞—Ç—á–∞–º–∏)...")
            
            telegram_texts = []
            telegram_indices = []
            
            for idx, tg_task in enumerate(telegram_tasks):
                tg_title = tg_task.get('title', '')
                tg_desc = tg_task.get('description', '')
                tg_context = tg_task.get('context', '')
                # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é:
                # title + description + –ø–µ—Ä–≤—ã–µ 1500 —Å–∏–º–≤–æ–ª–æ–≤ context (–≤–∞–∂–Ω–µ–µ –Ω–∞—á–∞–ª–æ)
                # –≠—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ, —Ç–∞–∫ –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å—Ä–µ–¥–Ω—è—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                tg_context_compact = tg_context[:1500] if tg_context else ''
                tg_text = f"{tg_title} {tg_desc} {tg_context_compact}".strip()[:8000]
                telegram_texts.append(tg_text)
                telegram_indices.append(idx)
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏ (—Å –∫–µ—à–µ–º)
            if self.embedding_cache:
                telegram_embeddings = self.embedding_cache.get_embeddings_batch(
                    telegram_texts,
                    client=self.openai_client,
                    batch_size=100
                )
            else:
                # Fallback: –ø–æ–ª—É—á–∞–µ–º –±–∞—Ç—á–∞–º–∏ –±–µ–∑ –∫–µ—à–∞
                telegram_embeddings = []
                batch_size = 100
                for i in range(0, len(telegram_texts), batch_size):
                    batch_texts = telegram_texts[i:i+batch_size]
                    try:
                        response = self.openai_client.embeddings.create(
                            model="text-embedding-3-small",
                            input=batch_texts
                        )
                        batch_embeddings = [item.embedding for item in response.data]
                        telegram_embeddings.extend(batch_embeddings)
                        if verbose and (i // batch_size + 1) % 10 == 0:
                            print(f"      üì¶ –ë–∞—Ç—á {i // batch_size + 1}/{(len(telegram_texts)-1)//batch_size + 1}...", end='\r', flush=True)
                    except Exception as e:
                        if verbose:
                            print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ {i // batch_size + 1}: {e}")
                        # –î–æ–±–∞–≤–ª—è–µ–º None –¥–ª—è –æ—à–∏–±–æ–∫
                        telegram_embeddings.extend([None] * len(batch_texts))
            
            # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å -> —ç–º–±–µ–¥–¥–∏–Ω–≥
            for idx, embedding in zip(telegram_indices, telegram_embeddings):
                telegram_embeddings_map[idx] = embedding
            
            if verbose:
                successful = sum(1 for emb in telegram_embeddings if emb is not None)
                print(f"\n      ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {successful}/{len(telegram_tasks)}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É Telegram
        for tg_idx, tg_task in enumerate(telegram_tasks, 1):
            tg_title = tg_task.get('title', '')
            tg_desc = tg_task.get('description', '')
            tg_context = tg_task.get('context', '')
            # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é:
            # title + description + –ø–µ—Ä–≤—ã–µ 1500 —Å–∏–º–≤–æ–ª–æ–≤ context (–≤–∞–∂–Ω–µ–µ –Ω–∞—á–∞–ª–æ)
            # –≠—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ, —Ç–∞–∫ –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å—Ä–µ–¥–Ω—è—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            tg_context_compact = tg_context[:1500] if tg_context else ''
            tg_text = f"{tg_title} {tg_desc} {tg_context_compact}".strip()[:8000]
            
            if verbose:
                print(f"\n   [{tg_idx}/{len(telegram_tasks)}] üì± Telegram: {tg_title[:60]}...")
            
            # –®–∞–≥ 1: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫–Ω–∞ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–¥–∞—á–∏ Asana
            windowed_tasks = {}
            if self.use_time_windows and self.time_window_matcher:
                windowed_tasks = self.time_window_matcher.prioritize_tasks_by_windows(tg_task, asana_tasks)
                
                if verbose:
                    primary_count = len(windowed_tasks.get('primary', []))
                    extended_count = len(windowed_tasks.get('extended', []))
                    distant_count = len(windowed_tasks.get('distant', []))
                    print(f"      ‚è∞ –û–∫–Ω–∞: –æ—Å–Ω–æ–≤–Ω–æ–µ={primary_count}, —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ={extended_count}, –¥–∞–ª—å–Ω–µ–µ={distant_count}")
            else:
                # –ë–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
                windowed_tasks = {
                    'primary': asana_tasks,
                    'extended': [],
                    'distant': []
                }
            
            # –®–∞–≥ 2: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–∞–∑–≤–∞–Ω–∏–π
            tg_title_normalized = self.normalize_text(tg_title)
            best_match = None
            best_score = 0.0
            best_asana_idx = -1
            exact_match_found = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–∞—á–∞–ª–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ–∫–Ω–µ
            for window_name in ['primary', 'extended', 'distant']:
                window_tasks = windowed_tasks.get(window_name, [])
                for idx, asana_task in enumerate(window_tasks):
                    if asana_task.get('gid') in asana_matched:
                        continue
                    
                    asana_name = asana_task.get('name', '')
                    asana_name_normalized = self.normalize_text(asana_name)
                    
                    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    if tg_title_normalized == asana_name_normalized:
                        best_match = asana_task
                        best_score = 1.0
                        best_asana_idx = asana_task.get('gid')
                        exact_match_found = True
                        if verbose:
                            print(f"      ‚úÖ –¢–û–ß–ù–û–ï –°–û–í–ü–ê–î–ï–ù–ò–ï –ù–ê–ó–í–ê–ù–ò–ô! Score: 1.00 ‚Üí {asana_name[:50]}")
                        break
                    
                    # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    if tg_title_normalized in asana_name_normalized or asana_name_normalized in tg_title_normalized:
                        shorter = min(len(tg_title_normalized), len(asana_name_normalized))
                        longer = max(len(tg_title_normalized), len(asana_name_normalized))
                        if shorter > 0:
                            partial_score = shorter / longer
                            if partial_score > 0.7 and partial_score > best_score:
                                best_match = asana_task
                                best_score = partial_score
                                best_asana_idx = asana_task.get('gid')
                                exact_match_found = True
                                if verbose:
                                    print(f"      ‚úÖ –ß–ê–°–¢–ò–ß–ù–û–ï –°–û–í–ü–ê–î–ï–ù–ò–ï –ù–ê–ó–í–ê–ù–ò–ô! Score: {partial_score:.2f} ‚Üí {asana_name[:50]}")
                
                if exact_match_found:
                    break
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if exact_match_found and best_score >= similarity_threshold:
                matches.append((tg_task, best_match, best_score))
                telegram_matched.add(tg_idx - 1)
                asana_matched.add(best_asana_idx)
                if verbose:
                    print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ! Score: {best_score:.2f}")
                continue
            
            # –®–∞–≥ 3: –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
            if use_embeddings:
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ (–±–∞—Ç—á–∞–º–∏)
                    tg_embedding = telegram_embeddings_map.get(tg_idx - 1)
                    
                    if not tg_embedding:
                        if verbose:
                            print(f"      ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –≤—Å–µ—Ö –æ–∫–æ–Ω —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
                    all_candidates = []
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–∫–Ω–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
                    for window_name, window_tasks in [
                        ('primary', windowed_tasks.get('primary', [])),
                        ('extended', windowed_tasks.get('extended', [])),
                        ('distant', windowed_tasks.get('distant', []))
                    ]:
                        if not window_tasks:
                            continue
                        
                        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∑–∞–¥–∞—á –≤ –æ–∫–Ω–µ (—Å –∫–µ—à–µ–º)
                        asana_texts = []
                        asana_indices = []
                        
                        for idx, asana_task in enumerate(window_tasks):
                            if asana_task.get('gid') in asana_matched:
                                continue
                            
                            context = self.extract_asana_task_context(asana_task)
                            # –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é (–ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è)
                            asana_text = context.get('embedding_text', context['full_text'])[:8000]
                            asana_texts.append(asana_text)
                            asana_indices.append((idx, asana_task))
                        
                        if not asana_texts:
                            continue
                        
                        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏ (—Å –∫–µ—à–µ–º)
                        # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞—Ç—á–∏–Ω–≥ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç
                        if self.embedding_cache:
                            asana_embeddings = self.embedding_cache.get_embeddings_batch(
                                asana_texts,
                                client=self.openai_client,
                                batch_size=100  # OpenAI –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ 2048, –∏—Å–ø–æ–ª—å–∑—É–µ–º 100 –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                            )
                        else:
                            # Fallback: –±–∞—Ç—á–∏–Ω–≥ –±–µ–∑ –∫–µ—à–∞ (–≤–∞–∂–Ω–æ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç)
                            asana_embeddings = []
                            batch_size = 100
                            for i in range(0, len(asana_texts), batch_size):
                                batch_texts = asana_texts[i:i+batch_size]
                                try:
                                    response = self.openai_client.embeddings.create(
                                        model="text-embedding-3-small",
                                        input=batch_texts
                                    )
                                    batch_embeddings = [item.embedding for item in response.data]
                                    asana_embeddings.extend(batch_embeddings)
                                except Exception as e:
                                    if verbose:
                                        print(f"         ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ Asana: {e}")
                                    # –î–æ–±–∞–≤–ª—è–µ–º None –¥–ª—è –æ—à–∏–±–æ–∫
                                    asana_embeddings.extend([None] * len(batch_texts))
                        
                        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
                        for (idx, asana_task), embedding in zip(asana_indices, asana_embeddings):
                            if embedding is None:
                                continue
                            
                            similarity = cosine_similarity_embedding(tg_embedding, embedding)
                            
                            # –ü–æ—Ä–æ–≥–∏ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –æ–∫–Ω–∞
                            if window_name == 'primary':
                                min_score = low_threshold
                            elif window_name == 'extended':
                                min_score = low_threshold + 0.05  # –ß—É—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥
                            else:  # distant
                                min_score = similarity_threshold  # –¢–æ–ª—å–∫–æ –≤—ã—Å–æ–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                            
                            if similarity >= min_score:
                                all_candidates.append({
                                    'task': asana_task,
                                    'score': similarity,
                                    'window': window_name,
                                    'gid': asana_task.get('gid')
                                })
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ score
                    all_candidates.sort(key=lambda x: x['score'], reverse=True)
                    
                    # –ë–µ—Ä–µ–º —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–º–∞–∫—Å–∏–º—É–º 5 –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ–∫–Ω–∞, 3 –∏–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ, 2 –∏–∑ –¥–∞–ª—å–Ω–µ–≥–æ)
                    top_candidates = []
                    primary_count = 0
                    extended_count = 0
                    distant_count = 0
                    
                    for candidate in all_candidates:
                        window = candidate['window']
                        if window == 'primary' and primary_count < 5:
                            top_candidates.append(candidate)
                            primary_count += 1
                        elif window == 'extended' and extended_count < 3:
                            top_candidates.append(candidate)
                            extended_count += 1
                        elif window == 'distant' and distant_count < 2:
                            top_candidates.append(candidate)
                            distant_count += 1
                    
                    if top_candidates:
                        best_candidate = top_candidates[0]
                        best_match = best_candidate['task']
                        best_score = best_candidate['score']
                        best_asana_idx = best_candidate['gid']
                        
                        if verbose:
                            print(f"      üî¢ –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {best_score:.3f} (–æ–∫–Ω–æ: {best_candidate['window']}) ‚Üí {best_match.get('name', '')[:50]}")
                        
                        # –î–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                        needs_gpt5_check = False
                        if use_two_stage_matching and low_threshold <= best_score < similarity_threshold:
                            needs_gpt5_check = True
                            if verbose:
                                print(f"         ‚ö†Ô∏è  –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (score {best_score:.3f} < –ø–æ—Ä–æ–≥–∞ {similarity_threshold}), —Ç—Ä–µ–±—É–µ—Ç—Å—è GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞")
                        
                        # GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞
                        # –î–ª—è GPT-5 –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç (full_text) –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                        if needs_gpt5_check or (use_gpt5_verification and best_score >= similarity_threshold):
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ context –¥–ª—è GPT-5 (–ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ)
                            best_match_context = self.extract_asana_task_context(best_match)
                            asana_text_full = best_match_context['full_text']
                            
                            # –î–ª—è Telegram —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π context –ø—Ä–∏ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–µ
                            tg_text_full = f"{tg_title} {tg_desc} {tg_context}".strip()[:8000]
                            
                            try:
                                gpt5_score = self.calculate_similarity(tg_text_full, asana_text_full, verbose=verbose)
                                if verbose:
                                    if needs_gpt5_check:
                                        print(f"         üîç GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {best_score:.3f} ‚Üí {gpt5_score:.2f}")
                                    else:
                                        print(f"         üîç GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞: {best_score:.3f} ‚Üí {gpt5_score:.2f}")
                                
                                if gpt5_score >= similarity_threshold:
                                    best_score = gpt5_score
                                    if verbose and needs_gpt5_check:
                                        print(f"         ‚úÖ GPT-5 –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ!")
                                else:
                                    if exact_match_found:
                                        if verbose:
                                            print(f"         ‚ö†Ô∏è  GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π")
                                    else:
                                        if verbose and needs_gpt5_check:
                                            print(f"         ‚ùå GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ")
                                        best_match = None
                                        best_score = 0.0
                                        best_asana_idx = -1
                            except Exception as e:
                                if verbose:
                                    print(f"         ‚ö†Ô∏è  –û—à–∏–±–∫–∞ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
                                if needs_gpt5_check:
                                    best_match = None
                                    best_score = 0.0
                                    best_asana_idx = -1
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
                    if best_match and best_score >= similarity_threshold:
                        matches.append((tg_task, best_match, best_score))
                        telegram_matched.add(tg_idx - 1)
                        asana_matched.add(best_asana_idx)
                        if verbose:
                            print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ! Score: {best_score:.2f} ‚Üí {best_match.get('name', '')[:50]}")
                    else:
                        if verbose:
                            print(f"      ‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ—Ä–æ–≥: {similarity_threshold})")
                
                except Exception as e:
                    if verbose:
                        print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {e}")
                        import traceback
                        traceback.print_exc()
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –Ω–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            if not best_match and verbose:
                print(f"      ‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Telegram
        telegram_only = [
            tg_task for idx, tg_task in enumerate(telegram_tasks)
            if idx not in telegram_matched
        ]
        
        # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Asana
        asana_only = [
            asana_task for asana_task in asana_tasks
            if asana_task.get('gid') not in asana_matched
        ]
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è
        coverage_analysis = analyze_coverage(matches, telegram_tasks, asana_tasks, self.context_extractor)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–µ—à –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º (–µ—Å–ª–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è)
        if self.embedding_cache:
            self.embedding_cache.flush_cache()
            if verbose:
                self.embedding_cache.print_cache_stats()
        
        return {
            'matches': matches,
            'telegram_only': telegram_only,
            'asana_only': asana_only,
            'coverage': coverage_analysis
        }
    
    def _analyze_coverage(
        self,
        matches: List[Tuple[Dict, Dict, float]],
        telegram_tasks: List[Dict[str, Any]],
        asana_tasks: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ report_generator)"""
        return analyze_coverage(matches, telegram_tasks, asana_tasks, self.context_extractor)
    
    def generate_sync_report(
        self,
        matching_result: Dict[str, List],
        output_file: Path
    ):
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ report_generator)"""
        return generate_sync_report(matching_result, output_file, self.context_extractor)
    
    def enrich_asana_task_with_telegram(
        self, 
        asana_task: Dict[str, Any], 
        telegram_task: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–î–æ–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É –∏–∑ Asana –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Telegram (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ task_transformer)"""
        return enrich_asana_task_with_telegram(asana_task, telegram_task)
    
    def create_asana_task_from_telegram(
        self, 
        telegram_task: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ –≤ Asana (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ task_transformer)"""
        return create_asana_task_from_telegram(
            telegram_task,
            workspace_gid=self.workspace_gid,
            project_gid=self.project_gid,
            assignee_gid=ASANA_USER_GID
        )
    


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
    project_root = Path(__file__).resolve().parent.parent.parent
    results_dir = project_root / "results" / "farma" / "extracted"
    sync_dir = project_root / "results" / "farma" / "sync"
    sync_dir.mkdir(parents=True, exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–¥–∞—á–∏ –∏–∑ Telegram
    telegram_tasks_file = results_dir / "farma_tasks_extracted.json"
    telegram_projects_file = results_dir / "farma_projects_extracted.json"
    
    sync = AsanaSync()
    
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ Telegram...")
    telegram_tasks = sync.load_telegram_tasks(telegram_tasks_file)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(telegram_tasks)} –∑–∞–¥–∞—á –∏–∑ Telegram")
    
    # TODO: –ó–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Asana —á–µ—Ä–µ–∑ MCP
    # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
    print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ Asana —Ç—Ä–µ–±—É–µ—Ç MCP –∫–ª–∏–µ–Ω—Ç–∞")
    print("   –î–ª—è –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ sync_with_mcp()")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∑–∞–¥–∞—á –∏–∑ Telegram
    telegram_structure = {
        'total_tasks': len(telegram_tasks),
        'by_status': {},
        'by_assignee': {}
    }
    
    for task in telegram_tasks:
        status = task.get('status', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        assignee = task.get('assignee', '–Ω–µ –Ω–∞–∑–Ω–∞—á–µ–Ω')
        
        telegram_structure['by_status'][status] = telegram_structure['by_status'].get(status, 0) + 1
        telegram_structure['by_assignee'][assignee] = telegram_structure['by_assignee'].get(assignee, 0) + 1
    
    structure_file = sync_dir / "telegram_tasks_structure.json"
    with open(structure_file, 'w', encoding='utf-8') as f:
        json.dump(telegram_structure, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–¥–∞—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {structure_file}")
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {telegram_structure['total_tasks']}")
    print(f"   –ü–æ —Å—Ç–∞—Ç—É—Å–∞–º: {telegram_structure['by_status']}")
    print(f"   –ü–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º: {telegram_structure['by_assignee']}")


if __name__ == "__main__":
    main()

