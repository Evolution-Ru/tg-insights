#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞—á –º–µ–∂–¥—É Telegram –∏ Asana
–î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω—è—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è: –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
"""
import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import re

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
_script_dir = Path(__file__).resolve().parent
_project_root = _script_dir.parent.parent.parent
if str(_project_root) not in sys.path:
    sys.path.insert(0, str(_project_root))

from scripts.analysis.utils.gpt5_client import get_openai_client
from scripts.analysis.embeddings.embeddings import get_embedding, cosine_similarity_embedding


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Asana
ASANA_WORKSPACE_GID = "624391999090674"
ASANA_USER_GID = "1169547205416171"
ASANA_PROJECT_GID = "1210655252186716"  # –§–∞—Ä–º–∞+
ASANA_ESTIMATED_TIME_FIELD_GID = "1204112099563346"


class AsanaSync:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞—á –º–µ–∂–¥—É Telegram –∏ Asana"""
    
    def __init__(self, mcp_client=None, openai_client=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            mcp_client: –ö–ª–∏–µ–Ω—Ç MCP –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Asana API
            openai_client: –ö–ª–∏–µ–Ω—Ç OpenAI –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        self.mcp_client = mcp_client
        self.openai_client = openai_client or get_openai_client()
        self.workspace_gid = ASANA_WORKSPACE_GID
        self.project_gid = ASANA_PROJECT_GID
        
    def load_telegram_tasks(self, tasks_file: Path) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Telegram –∞–Ω–∞–ª–∏–∑–∞"""
        with open(tasks_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('unique_tasks', [])
    
    def load_telegram_projects(self, projects_file: Path) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–µ–∫—Ç—ã –∏–∑ Telegram –∞–Ω–∞–ª–∏–∑–∞"""
        with open(projects_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('projects', [])
    
    def normalize_text(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        if not text:
            return ""
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = text.lower().strip()
        # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –¥–ª—è –±–æ–ª–µ–µ –≥–∏–±–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        text = re.sub(r'[^\w\s]', ' ', text)
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text)
        return text
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ GPT-5
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1
        """
        if not text1 or not text2:
            return 0.0
        
        prompt = f"""–°—Ä–∞–≤–Ω–∏ –¥–≤–∞ —Ç–µ–∫—Å—Ç–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω–∏ –ø–æ—Ö–æ–∂–∏ –ø–æ —Å–º—ã—Å–ª—É (–Ω–µ –ø–æ —Å–ª–æ–≤–∞–º, –∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é).

–¢–µ–∫—Å—Ç 1: {text1[:500]}
–¢–µ–∫—Å—Ç 2: {text2[:500]}

–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 1, –≥–¥–µ:
- 1.0 = —ç—Ç–æ –æ–¥–Ω–∞ –∏ —Ç–∞ –∂–µ –∑–∞–¥–∞—á–∞/—Ç–µ–º–∞
- 0.8-0.9 = –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–µ –∑–∞–¥–∞—á–∏, –Ω–æ –µ—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏—è
- 0.6-0.7 = —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏, –Ω–æ —Ä–∞–∑–Ω—ã–µ
- 0.3-0.5 = —á–∞—Å—Ç–∏—á–Ω–æ —Å–≤—è–∑–∞–Ω—ã
- 0.0-0.2 = —Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏

–¢–æ–ª—å–∫–æ —á–∏—Å–ª–æ, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π:"""
        
        try:
            response = self.openai_client.responses.create(
                model="gpt-5",
                input=[{"role": "user", "content": prompt}],
                reasoning={"effort": "low"}
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ –æ—Ç–≤–µ—Ç–∞
            if hasattr(response, 'output') and response.output:
                if isinstance(response.output, list) and len(response.output) > 0:
                    output_item = response.output[0]
                    if hasattr(output_item, 'content') and output_item.content:
                        if isinstance(output_item.content, list) and len(output_item.content) > 0:
                            content_item = output_item.content[0]
                            if hasattr(content_item, 'text'):
                                result_text = content_item.text.strip()
                            elif isinstance(content_item, dict) and 'text' in content_item:
                                result_text = content_item['text'].strip()
                            else:
                                result_text = str(content_item).strip()
                        else:
                            result_text = str(output_item.content).strip()
                    elif isinstance(output_item, dict):
                        if 'content' in output_item:
                            content = output_item['content']
                            if isinstance(content, list) and len(content) > 0:
                                if isinstance(content[0], dict) and 'text' in content[0]:
                                    result_text = content[0]['text'].strip()
                                else:
                                    result_text = str(content[0]).strip()
                            else:
                                result_text = str(content).strip()
                        else:
                            result_text = str(output_item).strip()
                    else:
                        result_text = str(output_item).strip()
                else:
                    result_text = str(response.output).strip()
            else:
                result_text = str(response).strip()
            
            # –ò—â–µ–º —á–∏—Å–ª–æ –≤ –æ—Ç–≤–µ—Ç–µ
            match = re.search(r'0?\.\d+|1\.0|0|1', result_text)
            if match:
                similarity = float(match.group())
                return min(max(similarity, 0.0), 1.0)
            return 0.5  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å
        except Exception as e:
            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            return self._simple_similarity(text1, text2)
    
    def _simple_similarity(self, text1: str, text2: str) -> float:
        """–ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (fallback)"""
        words1 = set(self.normalize_text(text1).split())
        words2 = set(self.normalize_text(text2).split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1 & words2
        union = words1 | words2
        
        return len(intersection) / len(union) if union else 0.0
    
    def find_matching_tasks(
        self, 
        telegram_tasks: List[Dict[str, Any]], 
        asana_tasks: List[Dict[str, Any]],
        similarity_threshold: float = 0.7,
        verbose: bool = True,
        max_asana_tasks: Optional[int] = None,
        use_embeddings: bool = True,
        use_gpt5_verification: bool = False  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ GPT-5 (–¥–æ—Ä–æ–≥–æ!)
    ) -> Dict[str, List[Tuple[Dict, Dict, float]]]:
        """
        –ù–∞–π—Ç–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏ –∏–∑ Telegram –∏ Asana
        
        Args:
            telegram_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Telegram
            asana_tasks: –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –∏–∑ Asana
            similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0-1.0) - –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –æ–±—ã—á–Ω–æ 0.7-0.8
            verbose: –í—ã–≤–æ–¥–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
            max_asana_tasks: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á Asana –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∞)
            use_embeddings: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
            use_gpt5_verification: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPT-5 –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–¥–æ—Ä–æ–≥–æ!)
        
        Returns:
            Dict —Å –∫–ª—é—á–∞–º–∏:
            - 'matches': —Å–ø–∏—Å–æ–∫ (telegram_task, asana_task, similarity_score)
            - 'telegram_only': –∑–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Telegram
            - 'asana_only': –∑–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Asana
        """
        matches = []
        telegram_matched = set()
        asana_matched = set()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á Asana –¥–ª—è —Ç–µ—Å—Ç–∞
        if max_asana_tasks:
            asana_tasks = asana_tasks[:max_asana_tasks]
            if verbose:
                print(f"   ‚ö†Ô∏è  –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å {max_asana_tasks} –∑–∞–¥–∞—á–∞–º–∏ Asana")
        
        if verbose:
            print(f"   üìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {len(telegram_tasks)} Telegram √ó {len(asana_tasks)} Asana")
        
        # –®–∞–≥ 1: –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á Asana (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏)
        if use_embeddings:
            if verbose:
                print(f"\n   üî¢ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(asana_tasks)} –∑–∞–¥–∞—á Asana...")
            
            asana_embeddings = []
            asana_texts = []
            for idx, asana_task in enumerate(asana_tasks):
                asana_name = asana_task.get('name', '')
                asana_notes = asana_task.get('notes', '') or ''
                asana_text = f"{asana_name} {asana_notes}".strip()[:8000]
                asana_texts.append(asana_text)
                
                if verbose and (idx + 1) % 20 == 0:
                    print(f"      üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx + 1}/{len(asana_tasks)}...", end='\r', flush=True)
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –±–∞—Ç—á–∞–º–∏
            try:
                if verbose:
                    print(f"      üîÑ –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ API...")
                
                # OpenAI embeddings API –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–∞—Ç—á–∏ –¥–æ 2048 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                batch_size = 100
                for i in range(0, len(asana_texts), batch_size):
                    batch_texts = asana_texts[i:i+batch_size]
                    batch_response = self.openai_client.embeddings.create(
                        model="text-embedding-3-small",
                        input=batch_texts
                    )
                    batch_embeddings = [item.embedding for item in batch_response.data]
                    asana_embeddings.extend(batch_embeddings)
                    
                    if verbose:
                        print(f"      ‚úÖ –ë–∞—Ç—á {i//batch_size + 1}/{(len(asana_texts)-1)//batch_size + 1} –≥–æ—Ç–æ–≤", end='\r', flush=True)
                
                if verbose:
                    print(f"\n      ‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è Asana –≥–æ—Ç–æ–≤—ã ({len(asana_embeddings)} —à—Ç.)")
            except Exception as e:
                if verbose:
                    print(f"\n      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ GPT-5")
                use_embeddings = False
        
        # –®–∞–≥ 2: –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É –∏–∑ Telegram —Å –∑–∞–¥–∞—á–∞–º–∏ Asana
        if verbose:
            print(f"\n   üîç –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π...")
            if use_embeddings:
                cost_info = "üí∞ –î–µ—à–µ–≤–æ (—Ç–æ–ª—å–∫–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏)"
                if use_gpt5_verification:
                    cost_info += " + GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞ (–¥–æ—Ä–æ–∂–µ)"
                print(f"      ‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ {cost_info}")
            else:
                print(f"      üêå –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-5 –¥–ª—è –≤—Å–µ—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π (–º–µ–¥–ª–µ–Ω–Ω–æ –∏ –¥–æ—Ä–æ–≥–æ)")
        
        for tg_idx, tg_task in enumerate(telegram_tasks, 1):
            tg_title = tg_task.get('title', '')
            tg_desc = tg_task.get('description', '')
            tg_text = f"{tg_title} {tg_desc}".strip()[:8000]
            
            if verbose:
                print(f"\n   [{tg_idx}/{len(telegram_tasks)}] üì± Telegram: {tg_title[:60]}...")
            
            best_match = None
            best_score = 0.0
            best_asana_idx = -1
            
            if use_embeddings:
                # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–¥–µ—à–µ–≤–æ!)
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–¥–∞—á–∏ Telegram
                    tg_embedding = get_embedding(tg_text, client=self.openai_client)
                    if not tg_embedding:
                        if verbose:
                            print(f"      ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å —Å–æ –≤—Å–µ–º–∏ –∑–∞–¥–∞—á–∞–º–∏ Asana
                    candidates = []
                    for idx, asana_embedding in enumerate(asana_embeddings):
                        if idx in asana_matched:
                            continue
                        
                        similarity = cosine_similarity_embedding(tg_embedding, asana_embedding)
                        candidates.append((idx, similarity))
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –±–µ—Ä–µ–º –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
                    candidates.sort(key=lambda x: x[1], reverse=True)
                    
                    if candidates:
                        best_asana_idx, best_score = candidates[0]
                        best_match = asana_tasks[best_asana_idx]
                        
                        if verbose:
                            print(f"      üî¢ –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {best_score:.3f} ‚Üí {best_match.get('name', '')[:50]}")
                        
                        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ GPT-5 (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
                        if use_gpt5_verification and best_score >= similarity_threshold:
                            asana_name = best_match.get('name', '')
                            asana_notes = best_match.get('notes', '') or ''
                            asana_text = f"{asana_name} {asana_notes}"
                            
                            try:
                                gpt5_score = self.calculate_similarity(tg_text, asana_text)
                                if verbose:
                                    print(f"         üîç GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∞: {best_score:.3f} ‚Üí {gpt5_score:.2f}")
                                
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-5 –æ—Ü–µ–Ω–∫—É –µ—Å–ª–∏ –æ–Ω–∞ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
                                if gpt5_score >= similarity_threshold:
                                    best_score = gpt5_score
                                else:
                                    # GPT-5 –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º
                                    best_match = None
                                    best_score = 0.0
                                    best_asana_idx = -1
                            except Exception as e:
                                if verbose:
                                    print(f"         ‚ö†Ô∏è  –û—à–∏–±–∫–∞ GPT-5 –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ü–µ–Ω–∫—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
                    if best_score < similarity_threshold:
                        best_match = None
                        best_score = 0.0
                        best_asana_idx = -1
                
                except Exception as e:
                    if verbose:
                        print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {e}, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ GPT-5")
                    use_embeddings = False
            
            # Fallback: –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ–±–æ—Ä —á–µ—Ä–µ–∑ GPT-5 (–µ—Å–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç)
            if not use_embeddings:
                # –ï—Å–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º GPT-5 –¥–ª—è –≤—Å–µ—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
                comparisons_done = 0
                for idx, asana_task in enumerate(asana_tasks):
                    if idx in asana_matched:
                        continue
                    
                    asana_name = asana_task.get('name', '')
                    asana_notes = asana_task.get('notes', '') or ''
                    asana_text = f"{asana_name} {asana_notes}"
                    
                    comparisons_done += 1
                    if verbose and comparisons_done % 10 == 0:
                        print(f"      üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ {comparisons_done}/{len(asana_tasks)}...", end='\r', flush=True)
                    
                    try:
                        score = self.calculate_similarity(tg_text, asana_text)
                        
                        if score > best_score and score >= similarity_threshold:
                            best_score = score
                            best_match = asana_task
                            best_asana_idx = idx
                    except Exception as e:
                        if verbose:
                            print(f"\n      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –∑–∞–¥–∞—á–µ–π '{asana_name[:40]}': {e}")
                        continue
            
            if best_match:
                matches.append((tg_task, best_match, best_score))
                telegram_matched.add(tg_idx - 1)  # tg_idx –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 1, –∏–Ω–¥–µ–∫—Å —Å 0
                asana_matched.add(best_asana_idx)
                if verbose:
                    print(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ! Score: {best_score:.2f} ‚Üí {best_match.get('name', '')[:50]}")
            else:
                if verbose:
                    print(f"      ‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–ø–æ—Ä–æ–≥: {similarity_threshold})")
        
        # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Telegram
        telegram_only = [
            tg_task for idx, tg_task in enumerate(telegram_tasks)
            if idx not in telegram_matched
        ]
        
        # –ó–∞–¥–∞—á–∏ —Ç–æ–ª—å–∫–æ –≤ Asana
        asana_only = [
            asana_task for idx, asana_task in enumerate(asana_tasks)
            if idx not in asana_matched
        ]
        
        return {
            'matches': matches,
            'telegram_only': telegram_only,
            'asana_only': asana_only
        }
    
    def enrich_asana_task_with_telegram(
        self, 
        asana_task: Dict[str, Any], 
        telegram_task: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        –î–æ–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É –∏–∑ Asana –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Telegram
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é
        """
        updates = {}
        
        asana_notes = asana_task.get('notes', '') or ''
        tg_desc = telegram_task.get('description', '')
        tg_context = telegram_task.get('context', '')
        
        # –ï—Å–ª–∏ –≤ Asana –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ –æ–Ω–æ –∫–æ—Ä–æ—á–µ, –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑ Telegram
        if not asana_notes or len(asana_notes) < len(tg_desc):
            updates['notes'] = f"{asana_notes}\n\n--- –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ Telegram ---\n{tg_desc}\n\n{tg_context}".strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
        tg_status = telegram_task.get('status', '')
        asana_completed = asana_task.get('completed', False)
        
        if tg_status == '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' and not asana_completed:
            updates['completed'] = True
        elif tg_status == '–Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ' and asana_completed:
            updates['completed'] = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ–¥–ª–∞–π–Ω
        tg_deadline = telegram_task.get('deadline')
        asana_due_on = asana_task.get('due_on')
        
        if tg_deadline and not asana_due_on:
            # –ü–∞—Ä—Å–∏–º –¥–µ–¥–ª–∞–π–Ω –∏–∑ Telegram (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö)
            updates['due_on'] = self._parse_deadline(tg_deadline)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Ç–∞—Ö –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è—Ö
        tg_chats = telegram_task.get('chats', [])
        tg_thread = telegram_task.get('discussion_thread', '')
        
        if tg_chats or tg_thread:
            context_note = "\n\n--- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è ---\n"
            if tg_chats:
                context_note += f"–ß–∞—Ç—ã: {', '.join(tg_chats)}\n"
            if tg_thread:
                context_note += f"–¢–µ–º–∞ –æ–±—Å—É–∂–¥–µ–Ω–∏—è: {tg_thread}\n"
            
            if 'notes' not in updates:
                updates['notes'] = asana_notes
            updates['notes'] += context_note
        
        return updates
    
    def _parse_deadline(self, deadline_str: str) -> Optional[str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–µ–¥–ª–∞–π–Ω–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD"""
        if not deadline_str:
            return None
        
        # –ï—Å–ª–∏ —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
        if re.match(r'\d{4}-\d{2}-\d{2}', deadline_str):
            return deadline_str
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã
        # TODO: –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç
        return None
    
    def create_asana_task_from_telegram(
        self, 
        telegram_task: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏ –≤ Asana –∏–∑ Telegram –∑–∞–¥–∞—á–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è ASANA_CREATE_A_TASK
        """
        title = telegram_task.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
        description = telegram_task.get('description', '')
        context = telegram_task.get('context', '')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        notes = f"{description}\n\n--- –ö–æ–Ω—Ç–µ–∫—Å—Ç ---\n{context}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Ç–∞—Ö
        chats = telegram_task.get('chats', [])
        thread = telegram_task.get('discussion_thread', '')
        
        if chats or thread:
            notes += "\n\n--- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ---\n"
            if chats:
                notes += f"–ß–∞—Ç—ã: {', '.join(chats)}\n"
            if thread:
                notes += f"–¢–µ–º–∞: {thread}\n"
        
        task_data = {
            'name': title,
            'notes': notes,
            'assignee': ASANA_USER_GID,
            'projects': [ASANA_PROJECT_GID],
            'workspace': ASANA_WORKSPACE_GID
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ–¥–ª–∞–π–Ω –µ—Å–ª–∏ –µ—Å—Ç—å
        deadline = telegram_task.get('deadline')
        if deadline:
            parsed_deadline = self._parse_deadline(deadline)
            if parsed_deadline:
                task_data['due_on'] = parsed_deadline
        
        # –°—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        status = telegram_task.get('status', '')
        if status == '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ':
            task_data['completed'] = True
        
        return task_data
    
    def generate_sync_report(
        self,
        matching_result: Dict[str, List],
        output_file: Path
    ):
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_telegram_tasks': len(matching_result['matches']) + len(matching_result['telegram_only']),
                'total_asana_tasks': len(matching_result['matches']) + len(matching_result['asana_only']),
                'matched_tasks': len(matching_result['matches']),
                'telegram_only': len(matching_result['telegram_only']),
                'asana_only': len(matching_result['asana_only'])
            },
            'matches': [
                {
                    'telegram_task': match[0],
                    'asana_task': {
                        'gid': match[1].get('gid'),
                        'name': match[1].get('name'),
                        'notes': match[1].get('notes', '')[:200] + '...' if len(match[1].get('notes', '')) > 200 else match[1].get('notes', '')
                    },
                    'similarity_score': match[2],
                    'recommended_updates': self.enrich_asana_task_with_telegram(match[1], match[0])
                }
                for match in matching_result['matches']
            ],
            'telegram_only': matching_result['telegram_only'],
            'asana_only': [
                {
                    'gid': task.get('gid'),
                    'name': task.get('name'),
                    'notes': task.get('notes', '')[:200] + '...' if len(task.get('notes', '')) > 200 else task.get('notes', '')
                }
                for task in matching_result['asana_only']
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        return report


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
    project_root = Path(__file__).resolve().parent.parent.parent
    results_dir = project_root / "results" / "farma" / "extracted"
    sync_dir = project_root / "results" / "farma" / "sync"
    sync_dir.mkdir(parents=True, exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–¥–∞—á–∏ –∏–∑ Telegram
    telegram_tasks_file = results_dir / "farma_tasks_extracted.json"
    telegram_projects_file = results_dir / "farma_projects_extracted.json"
    
    sync = AsanaSync()
    
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ Telegram...")
    telegram_tasks = sync.load_telegram_tasks(telegram_tasks_file)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(telegram_tasks)} –∑–∞–¥–∞—á –∏–∑ Telegram")
    
    # TODO: –ó–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–¥–∞—á–∏ –∏–∑ Asana —á–µ—Ä–µ–∑ MCP
    # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
    print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–¥–∞—á –∏–∑ Asana —Ç—Ä–µ–±—É–µ—Ç MCP –∫–ª–∏–µ–Ω—Ç–∞")
    print("   –î–ª—è –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ sync_with_mcp()")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∑–∞–¥–∞—á –∏–∑ Telegram
    telegram_structure = {
        'total_tasks': len(telegram_tasks),
        'by_status': {},
        'by_assignee': {}
    }
    
    for task in telegram_tasks:
        status = task.get('status', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        assignee = task.get('assignee', '–Ω–µ –Ω–∞–∑–Ω–∞—á–µ–Ω')
        
        telegram_structure['by_status'][status] = telegram_structure['by_status'].get(status, 0) + 1
        telegram_structure['by_assignee'][assignee] = telegram_structure['by_assignee'].get(assignee, 0) + 1
    
    structure_file = sync_dir / "telegram_tasks_structure.json"
    with open(structure_file, 'w', encoding='utf-8') as f:
        json.dump(telegram_structure, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–¥–∞—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {structure_file}")
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {telegram_structure['total_tasks']}")
    print(f"   –ü–æ —Å—Ç–∞—Ç—É—Å–∞–º: {telegram_structure['by_status']}")
    print(f"   –ü–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º: {telegram_structure['by_assignee']}")


if __name__ == "__main__":
    main()

